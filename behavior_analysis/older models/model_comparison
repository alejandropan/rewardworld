#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Sun Jul  5 21:42:25 2020

@author: alex
"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu May 21 18:52:51 2020

@author: alex
"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Sun May 10 19:13:18 2020

@author: alex
"""
import numpy as np
import scipy.optimize as so
import time
import sys
import pickle
import pandas as pd
import matplotlib.pyplot as plt
from rew_alf.data_organizers import *
import seaborn as sns
from scipy.stats.distributions import chi2
from scipy.stats import norm
import random
from matplotlib.lines import Line2D
import os
import glob
from os import path
from scipy.integrate import quad


def model_control():
    
    def true_stim_posterior(true_contrast, beliefSTD):
    	# Compute distribution over perceived contrast
    	# start_time = time.time()
    
    	def f(x):
    		return norm.cdf(x,0,beliefSTD) * norm.pdf(x,true_contrast,beliefSTD)
        
    	bs_right = quad(f,-np.inf, +np.inf)
    	return [1-bs_right[0],bs_right[0]]
    
    
    # Given all of the Q values (a matrix of size num_contrasts x 2), compute the overall Q_left and Q_right 
    # (i.e., the overall value of choosing left or right) given the perceived stimulus
    def compute_QL_QR(Q, trial_contrast, contrast_posterior):
    	Q_L = 0
    	Q_R = 0
    
    	# We compute Q_L, Q_R as in the Cell paper, by taking the weighted average of the various perceived stimuli,
    	# according to the probability that they were perceived
    	for i in range(len(contrast_posterior)):
    		Q_L += contrast_posterior[i] * Q[i, 0]
    		Q_R += contrast_posterior[i] * Q[i, 1]
    
    	return Q_L, Q_R
    
    def softmax_stay(Q_L, Q_R, beta, l_stay, r_stay, stay):
    	p = [np.exp(Q_L / beta + stay*l_stay),
          np.exp(Q_R / beta + stay*r_stay)]
    	p /= np.sum(p)
    
    	return p
    
    def trial_log_likelihood_stay(params, trial_data, Q, all_contrasts, all_posteriors, 
                                  previous_trial, trial_num, retrieve_Q = False, retrieve_ITIQ = False):
    	# Get relevant parameters
    	trial_contrast, trial_choice, reward, laser = trial_data
    	learning_rate, beliefSTD, extraVal, beta, stay = params
    	Q =  Q.copy()
    
    	# Compute the log-likelihood of the actual mouse choice
    	if all_posteriors is None:
    		contrast_posterior = true_stim_posterior(trial_contrast, beliefSTD)
    	else:
    		posterior_idx = np.argmin(np.abs(all_contrasts - trial_contrast))
    		contrast_posterior = all_posteriors[posterior_idx, :]
    
    	Q_L, Q_R = compute_QL_QR(Q, trial_contrast, contrast_posterior)
    	if trial_num == 0:
    		(l_stay, r_stay) = [0,0]
    	else:
    		previous_choice= [0,0]
    		previous_choice[previous_trial] = 1
    		(l_stay, r_stay) = previous_choice
        
    	choice_dist = softmax_stay(Q_L, Q_R, beta,l_stay, r_stay, stay)
    	LL = np.log(choice_dist[trial_choice])	
    
    	# Learning
    	if trial_choice == 0:
    		Q_chosen = Q_L
    	else:
    		Q_chosen = Q_R
    
    	# Laser-modulation
    	if laser == 1:
    		received_reward = reward + extraVal
    	else:
    		received_reward = reward
    
    	# Update Q-values according to the aggregate reward + laser value
    	for i in range(2):
    		Q[i, trial_choice] += contrast_posterior[i] * learning_rate * (received_reward - Q_chosen)
    
    	if retrieve_ITIQ == True:
    		Q_L = np.sum(Q, axis=0)[0]
    		Q_R = np.sum(Q, axis=0)[1]
    
    
    	if retrieve_Q==True:
    		return LL, Q, Q_L, Q_R, choice_dist[1] #  choice_dist[1] = pChoice_right
        
    	else:
    		return LL, Q
    
    
    
    def session_neg_log_likelihood_stay(params, *data, pregen_all_posteriors=True, 
                                        accu=False, retrieve_Q =  False, retrieve_ITIQ = False):
    	# Unpack the arguments
    	learning_rate, beliefSTD, extraVal, beta, stay = params
    	rewards, true_contrasts, choices, lasers = data
    	num_trials = len(rewards)
        
    	if retrieve_Q==True:
    		Q_L = []
    		Q_R = []
    		pRight = []
    
    	# Generate the possible contrast list
    	all_contrasts = np.array([-0.25, -0.125, -0.0625, 0, 0.0625, 0.125, 0.25])
    	num_contrasts = len(all_contrasts)
    
    	# If True, generate all posterior distributions ahead of time to save time
    	if pregen_all_posteriors:
    		all_posteriors = np.zeros((num_contrasts, 2))
    		for idx, contrast in enumerate(all_contrasts):
    			all_posteriors[idx, :] = true_stim_posterior(contrast, beliefSTD)
    	else:
    		all_posteriors = None
    
    	# Compute the log-likelihood
    	if accu == True:
    		acc = 0
    	LL = 0
    	Q = np.zeros([2, 2])
        
    	if retrieve_Q == True:
                
    		for i in range(num_trials):
    			if i == 0:
    			    trial_LL, newQ, Q_Lt, Q_Rt, pright = trial_log_likelihood_stay(params, 
                                                [true_contrasts[i], choices[i], rewards[i], lasers[i]], 
                                                Q, all_contrasts, all_posteriors, 
                                                np.nan, i, retrieve_Q=retrieve_Q, retrieve_ITIQ=retrieve_ITIQ)
    			else:
    			    trial_LL, newQ, Q_Lt, Q_Rt, pright = trial_log_likelihood_stay(params, 
                                                [true_contrasts[i], choices[i], rewards[i], lasers[i]], 
                                                Q, all_contrasts, all_posteriors, 
                                                choices[i-1], i, retrieve_Q=retrieve_Q, retrieve_ITIQ=retrieve_ITIQ)
    
    			if (i != 0) & (np.sum(Q, axis=0)[0] != np.sum(newQ, axis=0)[0]) & (np.sum(Q, axis=0)[1] != np.sum(newQ, axis=0)[1]):
    				print('Warning, double update error in trial %d'%i)
    			LL += trial_LL
    			Q = newQ
                
    			if accu == True:
    				acc += (np.exp(trial_LL)>0.5)*1
                
    			Q_L.append(Q_Lt)
    			Q_R.append(Q_Rt)
    			pRight.append(pright)
            
    		
    	else:        
    		for i in range(num_trials):
    			if i == 0:
    			    trial_LL, newQ = trial_log_likelihood_stay(params, 
                                                [true_contrasts[i], choices[i], rewards[i], lasers[i]], 
                                                Q, all_contrasts, all_posteriors, np.nan, i)
    			else:
    			    trial_LL, newQ = trial_log_likelihood_stay(params, 
                                                [true_contrasts[i], choices[i], rewards[i], lasers[i]], 
                                                Q, all_contrasts, all_posteriors, choices[i-1], i)
    			LL += trial_LL
    			Q = newQ
                
    			if accu == True:
    				acc += (np.exp(trial_LL)>0.5)*1
                    
    
    	if retrieve_Q == True:   
    		if accu == True:
    			acc = acc/num_trials
    			return -LL,  acc, Q_L, Q_R, pRight
    		else:
    			return -LL, Q_L, Q_R, pRight
    
    	else:
    		if accu == True:
    			acc = acc/num_trials
    			return -LL,  acc
    		else:
    			return -LL
    
    
    
    
    
    # Optimize several times with different initializations and return the best fit parameters, and negative log likelihood
    
    def optimizer_stay(data, num_fits = 4, initial_guess=[0.1, 1, 0, 1, 1]):
    	# Accounting variables
    	best_NLL = np.Inf
    	best_x = [None, None, None, None, None]
    	buffer_NLL = []
    	buffer_x = np.empty([num_fits,len(initial_guess)])
    	# Do our fit with several different initializations
    	for i in range(num_fits):
    		print('Starting fit %d' % i)
    
    		# For every fit other than the first, construct a new initial guess
    		if i != 0:
    			lr_guess = np.random.uniform(0, 2)
    			beliefSTD_guess = np.random.uniform(0.03, 1)
    			extraVal_guess = np.random.uniform(-2,2)
    			beta_guess = np.random.uniform(0.01, 1)
    			stay = np.random.uniform(-1, 1)
    			initial_guess = [lr_guess, beliefSTD_guess, extraVal_guess, beta_guess, stay]
    
    		# Run the fit
    		res = so.minimize(session_neg_log_likelihood_stay, initial_guess, args=data, 
                        method='L-BFGS-B', bounds=[(0, 2), (0.03, 1), (-2, 2), (0.01, 1), 
                                        (-1,1)])
    
    		# If this fit is better than the previous best, remember it, otherwise toss
    		buffer_x[i,:] = res.x
    		buffer_NLL.append(res.fun)
            
    		if res.fun <= best_NLL:
    			best_NLL = res.fun
    			best_x = res.x
    
    	return best_x, best_NLL, buffer_NLL, buffer_x
    
    
    
    # hardcode this for speed
    def normal_pdf(x, loc, scale):
    	factor = 1 / (np.sqrt(2 * np.pi) * scale)
    	power = -0.5 * (((x - loc) / scale) ** 2)
    
    	return factor * np.exp(power)
    
    ##### Analysis functions
    
    def accuracy_per_contrast(data, all_contrasts):
    	rewards, contrasts, choices, lasers = data
    	num_trials = len(rewards)
    
    	acc = np.zeros(len(all_contrasts))
    	trials_per_contrast = np.zeros(len(all_contrasts))
    	for i in range(num_trials):
    		reward = rewards[i]
    		contrast = contrasts[i]
    		choice = choices[i]
    		laser = lasers[i]
    
    		contrast_idx = np.argmin(np.abs(all_contrasts - contrast))
    		
    		if reward > 0:
    			acc[contrast_idx] += 1
    
    		trials_per_contrast[contrast_idx] += 1
    
    	acc /= trials_per_contrast
    
    	return acc
    
    def psychometric_curve(data, all_contrasts):
    	rewards, contrasts, choices, lasers = data
    	num_trials = len(rewards)
    
    	p_right = np.zeros(len(all_contrasts))
    	trials_per_contrast = np.zeros(len(all_contrasts))
    	for i in range(num_trials):
    		reward = rewards[i]
    		contrast = contrasts[i]
    		choice = choices[i]
    		laser = lasers[i]
    
    		contrast_idx = np.argmin(np.abs(all_contrasts - contrast))
    		
    		if choice == 1:
    			p_right[contrast_idx] += 1
    
    		trials_per_contrast[contrast_idx] += 1
    
    	p_right /= trials_per_contrast
    
    	return p_right
    
    ##### TESTING SCRIPT #####
    
    def simulation_contrast_distribution(mean_contrast, beliefSTD, all_contrasts):
    	# Compute distribution of final perceived contrasts
    	p = normal_pdf(all_contrasts, loc=mean_contrast, scale=beliefSTD)
    
    	# Renormalize
    	p /= np.sum(p)
    
    	return p
    
    
    def generate_data_stay(data, all_contrasts, learning_rate=0.3, 
                           beliefSTD=0.1, extraVal=1, beta=0.2, 
                           stay = 1, is_verbose=False, propagate_errors = True):
    	
    	rewards = []
    	true_contrasts = []
    	choices = []
    	lasers = []
        
    	if propagate_errors == False:
    		prop = 3
    	else:
    		prop = 4
    
    	# Simulate the POMDP model
    	Q = np.zeros([2, 2])
    	for t in range(len(data[0])):
    		if is_verbose:
    			print(t)
    
    		# Pick a true stimulus and store
    		trial_contrast = data[1][t]
    		true_contrasts.append(trial_contrast)
            # Add noise
    		perceived_contrast_distribution = simulation_contrast_distribution(trial_contrast, beliefSTD, all_contrasts)
    		perceived_contrast = np.random.choice(all_contrasts, p=perceived_contrast_distribution)
            
    		contrast_posterior = [0,0]
    		contrast_posterior[0] = norm.cdf(0, loc = trial_contrast, scale = beliefSTD)
    		contrast_posterior[1] = 1 - contrast_posterior[0]
            
    		Q_L, Q_R = compute_QL_QR(Q, perceived_contrast, contrast_posterior)
    
    		if t == 0:
    		    (l_stay, r_stay) = [0,0]
    		else:
    		    previous_choice= [0,0]
    		    previous_choice[choices[t-1]] = 1
    		    (l_stay, r_stay) = previous_choice
    		choice_dist = softmax_stay(Q_L, Q_R, beta,l_stay, r_stay, stay)
    		choice = np.random.choice(2, p = [float(choice_dist[0]), float(choice_dist[1])])
    		choices.append(choice)
    
    		# Get reward and store it
    		if np.sign(trial_contrast) == -1 and choice == 0:
    			reward = 1
    		elif np.sign(trial_contrast) == 1 and choice == 1:
    			reward = 1
    		elif np.sign(trial_contrast) == 0:
    			reward = random.choice([0,1])      
    		else:
    			reward = 0
    
    		rewards.append(reward)
    		
    		# Add laser value on the correct condition
    		if propagate_errors == True:
    			if choice == data[prop][t]:
    			    reward += extraVal
    			    lasers.append(1)
    			else:
    			    lasers.append(-1)
    		else:
    			reward = data[0][t]
    			reward += extraVal*data[prop][t]
    			lasers.append(data[prop][t])
    		# Learn (update Q-values)
    		if choice == 0:
    			Q_chosen = Q_L
    		else:
    			Q_chosen = Q_R
            
    		contrast_posterior = [0,0]
    		contrast_posterior[0] = norm.cdf(0, loc = trial_contrast, scale = beliefSTD)
    		contrast_posterior[1] = 1 - contrast_posterior[0]
    
    		for i in range(2):
    			Q[i, choice] += contrast_posterior[i] * learning_rate * (reward - Q_chosen)
    
    	return rewards, true_contrasts, choices, lasers
    
    def transform_model_struct_2_POMDP(model_data, simulate_data):
            simulate_data.loc[simulate_data['extraRewardTrials'] == 'right', 'extraRewardTrials' ] = 1
            simulate_data.loc[simulate_data['extraRewardTrials'] == 'left', 'extraRewardTrials' ] = 0
            simulate_data.loc[simulate_data['extraRewardTrials'] == 'none', 'extraRewardTrials' ] = -1
            obj = model_data
            obj['choice'] = obj['choice'] * -1
            obj.loc[obj['choice'] == -1, 'choice'] = 0
            obj['laser_side'] = simulate_data['extraRewardTrials']
            return obj
    
    def likelihood_ratio(llmin, llmax):
        return(2*(llmax-llmin))
    
    def aic(LL,n_param):
        # Calculates Akaike Information Criterion
        aic =  2*n_param - 2*LL
        return aic
        
    def chi2_LLR(L1,L2):
        LR = likelihood_ratio(L1,L2)
        p = chi2.sf(LR, 1) # L2 has 1 DoF more than L1
        return p

    mice = np.array(['dop_8', 'dop_9', 'dop_11', 'dop_4', 'dop_7'])
    
    # Load Alex's actual data
    psy = pd.read_pickle('all_behav.pkl')
    
    train_set_size = 1
    cross_validate = False
         
    all_contrasts = np.array([-0.25  , -0.125 , -0.0625,  0.    ,  0.0625, 0.125 , 0.25  ])
    best_nphr_individual = np.zeros([len(psy.loc[psy['virus'] == 'nphr', 'mouse_name'].unique()),4])
    best_nphr_NLL_individual = np.zeros([len(psy.loc[psy['virus'] == 'nphr', 'mouse_name'].unique()),1])
    model_parameters = pd.DataFrame()
    modelled_data = pd.DataFrame()
    for i, mouse in enumerate(mice): 
            model_data_nphr, simulate_data_nphr  = \
                psy_df_to_Q_learning_model_format(psy.loc[psy['mouse_name'] == mouse], 
                                                  virus = psy.loc[psy['mouse_name'] == mouse, 'virus'].unique()[0])
            
            
            obj = transform_model_struct_2_POMDP(model_data_nphr, simulate_data_nphr)
            
            virus = psy.loc[psy['mouse_name'] == mouse, 'virus'].unique()[0]
            
            opto = obj['extraRewardTrials'].to_numpy()
            lasers = []
            for i in range(len(opto)):
                try:
                    lasers.append(int(opto[i][0]))
                except:
                    lasers.append(int(opto[i]))
        
            choices = list(obj['choice'].to_numpy())
            contrasts = list(obj['stimTrials'].to_numpy())
            rewards = list(obj['reward'].to_numpy())
            laser_side = list(obj['laser_side'].to_numpy())
        
            
            data = (rewards[:int(len(rewards)*train_set_size)],
                    contrasts[:int(len(rewards)*train_set_size)], 
                    choices[:int(len(rewards)*train_set_size)], 
                    lasers[:int(len(rewards)*train_set_size)])
            simulate_data = (rewards[:int(len(rewards)*train_set_size)], 
                             contrasts[:int(len(rewards)*train_set_size)], 
                             choices[:int(len(rewards)*train_set_size)], 
                          lasers[:int(len(rewards)*train_set_size)], 
                          laser_side[:int(len(rewards)*train_set_size)])
            
            if cross_validate == True:
                
                data = (rewards[:int(len(rewards)*train_set_size)],
                    contrasts[:int(len(rewards)*train_set_size)], 
                    choices[:int(len(rewards)*train_set_size)], 
                    lasers[:int(len(rewards)*train_set_size)])
                simulate_data_test = (rewards[int(len(rewards)*train_set_size):], 
                                      contrasts[int(len(rewards)*train_set_size):], 
                                      choices[int(len(rewards)*train_set_size):], 
                              lasers[int(len(rewards)*train_set_size):], 
                              laser_side[int(len(rewards)*train_set_size):])
            else:
                data_test = data
                simulate_data_test = simulate_data
            
    
            (best_x_stay, train_NLL_stay, buffer_NLL_stay, 
             buffer_x_stay) = optimizer_stay(data, initial_guess=[0.3, 0.05, -1, 0.2,1])
            
            cv_aic_stay = aic((session_neg_log_likelihood_stay(best_x_stay,
                      *data_test, pregen_all_posteriors=True))*-1,5)
            
           
            cv_LL_stay = (session_neg_log_likelihood_stay(best_x_stay, *data_test,
                                                          pregen_all_posteriors=True))*-1
           
            
            
            _, cv_acc_stay = session_neg_log_likelihood_stay(best_x_stay, *data_test, 
                           pregen_all_posteriors=True, accu=True)
           
            
            model_parameters_mouse = pd.DataFrame()
            model_parameters_mouse['x'] = [best_x_stay]
            model_parameters_mouse['LL'] = (cv_LL_stay/len(data_test[0]))
            model_parameters_mouse['aic'] = cv_aic_stay
            model_parameters_mouse['accu'] = cv_acc_stay
            model_parameters_mouse['model_name'] = 'w_stay'
    
            
            sim_data = generate_data_stay(simulate_data_test, all_contrasts, learning_rate=best_x_stay[0],
                                       beliefSTD=best_x_stay[1], extraVal=best_x_stay[2], beta=best_x_stay[3],
                                       stay =best_x_stay[4])
            sim_data = pd.DataFrame(sim_data)
            
            sim_data = sim_data.rename(columns={0: "rewards", 1: "signed_contrast", 2: "simulated_choices", 3: "model_laser"})
            sim_data = np.array(sim_data)
            sim_data = pd.DataFrame(sim_data).T
            sim_data['laser'] = lasers[:int(len(rewards)*train_set_size)]
            sim_data['laser_side'] = laser_side[:int(len(rewards)*train_set_size)]
            sim_data['real_choice'] = choices[:int(len(rewards)*train_set_size)]
            sim_data['mouse_name']  = mouse
            sim_data['virus']  = virus
            sim_data['real_rewards']  = simulate_data[0]
           
            # Concatenate with general dataframes
            model_parameters_mouse['mouse'] = mouse
            model_parameters_mouse['virus'] = virus
            
            # Concatenate with general dataframes
            model_parameters = pd.concat([model_parameters, model_parameters_mouse])
            modelled_data = pd.concat([modelled_data, sim_data])
    
    return model_parameters
            


def model_wo_stay():
    
    def true_stim_posterior(true_contrast, beliefSTD):
    	# Compute distribution over perceived contrast
    	# start_time = time.time()
    
    	def f(x):
    		return norm.cdf(x,0,beliefSTD) * norm.pdf(x,true_contrast,beliefSTD)
        
    	bs_right = quad(f,-np.inf, +np.inf)
    	return [1-bs_right[0],bs_right[0]]
    
    
    # Given all of the Q values (a matrix of size num_contrasts x 2), compute the overall Q_left and Q_right 
    # (i.e., the overall value of choosing left or right) given the perceived stimulus
    def compute_QL_QR(Q, trial_contrast, contrast_posterior):
    	Q_L = 0
    	Q_R = 0
    
    	# We compute Q_L, Q_R as in the Cell paper, by taking the weighted average of the various perceived stimuli,
    	# according to the probability that they were perceived
    	for i in range(len(contrast_posterior)):
    		Q_L += contrast_posterior[i] * Q[i, 0]
    		Q_R += contrast_posterior[i] * Q[i, 1]
    
    	return Q_L, Q_R
    
    def softmax_stay(Q_L, Q_R, beta):
    	p = [np.exp(Q_L / beta),
          np.exp(Q_R / beta)]
    	p /= np.sum(p)
    
    	return p
    
    def trial_log_likelihood_stay(params, trial_data, Q, all_contrasts, all_posteriors, 
                                  previous_trial, trial_num, retrieve_Q = False, retrieve_ITIQ = False):
    	# Get relevant parameters
    	trial_contrast, trial_choice, reward, laser = trial_data
    	learning_rate, beliefSTD, extraVal, beta = params
    	Q =  Q.copy()
    
    	# Compute the log-likelihood of the actual mouse choice
    	if all_posteriors is None:
    		contrast_posterior = true_stim_posterior(trial_contrast, beliefSTD)
    	else:
    		posterior_idx = np.argmin(np.abs(all_contrasts - trial_contrast))
    		contrast_posterior = all_posteriors[posterior_idx, :]
    
    	Q_L, Q_R = compute_QL_QR(Q, trial_contrast, contrast_posterior)
        
    	choice_dist = softmax_stay(Q_L, Q_R, beta)
    	LL = np.log(choice_dist[trial_choice])	
    
    	# Learning
    	if trial_choice == 0:
    		Q_chosen = Q_L
    	else:
    		Q_chosen = Q_R
    
    	# Laser-modulation
    	if laser == 1:
    		received_reward = reward + extraVal
    	else:
    		received_reward = reward
    
    	# Update Q-values according to the aggregate reward + laser value
    	for i in range(2):
    		Q[i, trial_choice] += contrast_posterior[i] * learning_rate * (received_reward - Q_chosen)
    
    	if retrieve_ITIQ == True:
    		Q_L = np.sum(Q, axis=0)[0]
    		Q_R = np.sum(Q, axis=0)[1]
    
    
    	if retrieve_Q==True:
    		return LL, Q, Q_L, Q_R, choice_dist[1] #  choice_dist[1] = pChoice_right
        
    	else:
    		return LL, Q
    
    
    
    def session_neg_log_likelihood_stay(params, *data, pregen_all_posteriors=True, 
                                        accu=False, retrieve_Q =  False, retrieve_ITIQ = False):
    	# Unpack the arguments
    	learning_rate, beliefSTD, extraVal, beta = params
    	rewards, true_contrasts, choices, lasers = data
    	num_trials = len(rewards)
        
    	if retrieve_Q==True:
    		Q_L = []
    		Q_R = []
    		pRight = []
    
    	# Generate the possible contrast list
    	all_contrasts = np.array([-0.25, -0.125, -0.0625, 0, 0.0625, 0.125, 0.25])
    	num_contrasts = len(all_contrasts)
    
    	# If True, generate all posterior distributions ahead of time to save time
    	if pregen_all_posteriors:
    		all_posteriors = np.zeros((num_contrasts, 2))
    		for idx, contrast in enumerate(all_contrasts):
    			all_posteriors[idx, :] = true_stim_posterior(contrast, beliefSTD)
    	else:
    		all_posteriors = None
    
    	# Compute the log-likelihood
    	if accu == True:
    		acc = 0
    	LL = 0
    	Q = np.zeros([2, 2])
        
    	if retrieve_Q == True:
                
    		for i in range(num_trials):
    			if i == 0:
    			    trial_LL, newQ, Q_Lt, Q_Rt, pright = trial_log_likelihood_stay(params, 
                                                [true_contrasts[i], choices[i], rewards[i], lasers[i]], 
                                                Q, all_contrasts, all_posteriors, 
                                                np.nan, i, retrieve_Q=retrieve_Q, retrieve_ITIQ=retrieve_ITIQ)
    			else:
    			    trial_LL, newQ, Q_Lt, Q_Rt, pright = trial_log_likelihood_stay(params, 
                                                [true_contrasts[i], choices[i], rewards[i], lasers[i]], 
                                                Q, all_contrasts, all_posteriors, 
                                                choices[i-1], i, retrieve_Q=retrieve_Q, retrieve_ITIQ=retrieve_ITIQ)
    
    			if (i != 0) & (np.sum(Q, axis=0)[0] != np.sum(newQ, axis=0)[0]) & (np.sum(Q, axis=0)[1] != np.sum(newQ, axis=0)[1]):
    				print('Warning, double update error in trial %d'%i)
    			LL += trial_LL
    			Q = newQ
                
    			if accu == True:
    				acc += (np.exp(trial_LL)>0.5)*1
                
    			Q_L.append(Q_Lt)
    			Q_R.append(Q_Rt)
    			pRight.append(pright)
            
    		
    	else:        
    		for i in range(num_trials):
    			if i == 0:
    			    trial_LL, newQ = trial_log_likelihood_stay(params, 
                                                [true_contrasts[i], choices[i], rewards[i], lasers[i]], 
                                                Q, all_contrasts, all_posteriors, np.nan, i)
    			else:
    			    trial_LL, newQ = trial_log_likelihood_stay(params, 
                                                [true_contrasts[i], choices[i], rewards[i], lasers[i]], 
                                                Q, all_contrasts, all_posteriors, choices[i-1], i)
    			LL += trial_LL
    			Q = newQ
                
    			if accu == True:
    				acc += (np.exp(trial_LL)>0.5)*1
                    
    
    	if retrieve_Q == True:   
    		if accu == True:
    			acc = acc/num_trials
    			return -LL,  acc, Q_L, Q_R, pRight
    		else:
    			return -LL, Q_L, Q_R, pRight
    
    	else:
    		if accu == True:
    			acc = acc/num_trials
    			return -LL,  acc
    		else:
    			return -LL
    
    
    
    
    
    # Optimize several times with different initializations and return the best fit parameters, and negative log likelihood
    
    def optimizer_stay(data, num_fits = 4, initial_guess=[0.1, 1, 0, 1]):
    	# Accounting variables
    	best_NLL = np.Inf
    	best_x = [None, None, None, None]
    	buffer_NLL = []
    	buffer_x = np.empty([num_fits,len(initial_guess)])
    	# Do our fit with several different initializations
    	for i in range(num_fits):
    		print('Starting fit %d' % i)
    
    		# For every fit other than the first, construct a new initial guess
    		if i != 0:
    			lr_guess = np.random.uniform(0, 2)
    			beliefSTD_guess = np.random.uniform(0.03, 1)
    			extraVal_guess = np.random.uniform(-2,2)
    			beta_guess = np.random.uniform(0.01, 1)
    			initial_guess = [lr_guess, beliefSTD_guess, extraVal_guess, beta_guess]
    
    		# Run the fit
    		res = so.minimize(session_neg_log_likelihood_stay, initial_guess, args=data, 
                        method='L-BFGS-B', bounds=[(0, 2), (0.03, 1), (-2, 2), (0.01, 1)])
    
    		# If this fit is better than the previous best, remember it, otherwise toss
    		buffer_x[i,:] = res.x
    		buffer_NLL.append(res.fun)
            
    		if res.fun <= best_NLL:
    			best_NLL = res.fun
    			best_x = res.x
    
    	return best_x, best_NLL, buffer_NLL, buffer_x
    
    
    
    # hardcode this for speed
    def normal_pdf(x, loc, scale):
    	factor = 1 / (np.sqrt(2 * np.pi) * scale)
    	power = -0.5 * (((x - loc) / scale) ** 2)
    
    	return factor * np.exp(power)
    
    ##### Analysis functions
    
    def accuracy_per_contrast(data, all_contrasts):
    	rewards, contrasts, choices, lasers = data
    	num_trials = len(rewards)
    
    	acc = np.zeros(len(all_contrasts))
    	trials_per_contrast = np.zeros(len(all_contrasts))
    	for i in range(num_trials):
    		reward = rewards[i]
    		contrast = contrasts[i]
    		choice = choices[i]
    		laser = lasers[i]
    
    		contrast_idx = np.argmin(np.abs(all_contrasts - contrast))
    		
    		if reward > 0:
    			acc[contrast_idx] += 1
    
    		trials_per_contrast[contrast_idx] += 1
    
    	acc /= trials_per_contrast
    
    	return acc
    
    def psychometric_curve(data, all_contrasts):
    	rewards, contrasts, choices, lasers = data
    	num_trials = len(rewards)
    
    	p_right = np.zeros(len(all_contrasts))
    	trials_per_contrast = np.zeros(len(all_contrasts))
    	for i in range(num_trials):
    		reward = rewards[i]
    		contrast = contrasts[i]
    		choice = choices[i]
    		laser = lasers[i]
    
    		contrast_idx = np.argmin(np.abs(all_contrasts - contrast))
    		
    		if choice == 1:
    			p_right[contrast_idx] += 1
    
    		trials_per_contrast[contrast_idx] += 1
    
    	p_right /= trials_per_contrast
    
    	return p_right
    
    ##### TESTING SCRIPT #####
    
    def simulation_contrast_distribution(mean_contrast, beliefSTD, all_contrasts):
    	# Compute distribution of final perceived contrasts
    	p = normal_pdf(all_contrasts, loc=mean_contrast, scale=beliefSTD)
    
    	# Renormalize
    	p /= np.sum(p)
    
    	return p
    
    
    def generate_data_stay(data, all_contrasts, learning_rate=0.3, 
                           beliefSTD=0.1, extraVal=1, beta=0.2, 
                           is_verbose=False, propagate_errors = True):
    	
    	rewards = []
    	true_contrasts = []
    	choices = []
    	lasers = []
        
    	if propagate_errors == False:
    		prop = 3
    	else:
    		prop = 4
    
    	# Simulate the POMDP model
    	Q = np.zeros([2, 2])
    	for t in range(len(data[0])):
    		if is_verbose:
    			print(t)
    
    		# Pick a true stimulus and store
    		trial_contrast = data[1][t]
    		true_contrasts.append(trial_contrast)
            # Add noise
    		perceived_contrast_distribution = simulation_contrast_distribution(trial_contrast, beliefSTD, all_contrasts)
    		perceived_contrast = np.random.choice(all_contrasts, p=perceived_contrast_distribution)
            
    		contrast_posterior = [0,0]
    		contrast_posterior[0] = norm.cdf(0, loc = trial_contrast, scale = beliefSTD)
    		contrast_posterior[1] = 1 - contrast_posterior[0]
            
    		Q_L, Q_R = compute_QL_QR(Q, perceived_contrast, contrast_posterior)
    
    		
    		
    		choice_dist = softmax_stay(Q_L, Q_R, beta)
    		choice = np.random.choice(2, p = [float(choice_dist[0]), float(choice_dist[1])])
    		choices.append(choice)
    
    		# Get reward and store it
    		if np.sign(trial_contrast) == -1 and choice == 0:
    			reward = 1
    		elif np.sign(trial_contrast) == 1 and choice == 1:
    			reward = 1
    		elif np.sign(trial_contrast) == 0:
    			reward = random.choice([0,1])      
    		else:
    			reward = 0
    
    		rewards.append(reward)
    		
    		# Add laser value on the correct condition
    		if propagate_errors == True:
    			if choice == data[prop][t]:
    			    reward += extraVal
    			    lasers.append(1)
    			else:
    			    lasers.append(-1)
    		else:
    			reward = data[0][t]
    			reward += extraVal*data[prop][t]
    			lasers.append(data[prop][t])
    		# Learn (update Q-values)
    		if choice == 0:
    			Q_chosen = Q_L
    		else:
    			Q_chosen = Q_R
            
    		contrast_posterior = [0,0]
    		contrast_posterior[0] = norm.cdf(0, loc = trial_contrast, scale = beliefSTD)
    		contrast_posterior[1] = 1 - contrast_posterior[0]
    
    		for i in range(2):
    			Q[i, choice] += contrast_posterior[i] * learning_rate * (reward - Q_chosen)
    
    	return rewards, true_contrasts, choices, lasers
    
    def transform_model_struct_2_POMDP(model_data, simulate_data):
            simulate_data.loc[simulate_data['extraRewardTrials'] == 'right', 'extraRewardTrials' ] = 1
            simulate_data.loc[simulate_data['extraRewardTrials'] == 'left', 'extraRewardTrials' ] = 0
            simulate_data.loc[simulate_data['extraRewardTrials'] == 'none', 'extraRewardTrials' ] = -1
            obj = model_data
            obj['choice'] = obj['choice'] * -1
            obj.loc[obj['choice'] == -1, 'choice'] = 0
            obj['laser_side'] = simulate_data['extraRewardTrials']
            return obj
    
    def likelihood_ratio(llmin, llmax):
        return(2*(llmax-llmin))
    
    def aic(LL,n_param):
        # Calculates Akaike Information Criterion
        aic =  2*n_param - 2*LL
        return aic
        
    def chi2_LLR(L1,L2):
        LR = likelihood_ratio(L1,L2)
        p = chi2.sf(LR, 1) # L2 has 1 DoF more than L1
        return p

    mice = np.array(['dop_8', 'dop_9', 'dop_11', 'dop_4', 'dop_7'])
    
    # Load Alex's actual data
    psy = pd.read_pickle('all_behav.pkl')
    
    train_set_size = 1
    cross_validate = False
         
    all_contrasts = np.array([-0.25  , -0.125 , -0.0625,  0.    ,  0.0625, 0.125 , 0.25  ])
    best_nphr_individual = np.zeros([len(psy.loc[psy['virus'] == 'nphr', 'mouse_name'].unique()),4])
    best_nphr_NLL_individual = np.zeros([len(psy.loc[psy['virus'] == 'nphr', 'mouse_name'].unique()),1])
    model_parameters = pd.DataFrame()
    modelled_data = pd.DataFrame()
    for i, mouse in enumerate(mice): 
            model_data_nphr, simulate_data_nphr  = \
                psy_df_to_Q_learning_model_format(psy.loc[psy['mouse_name'] == mouse], 
                                                  virus = psy.loc[psy['mouse_name'] == mouse, 'virus'].unique()[0])
            
            
            obj = transform_model_struct_2_POMDP(model_data_nphr, simulate_data_nphr)
            
            virus = psy.loc[psy['mouse_name'] == mouse, 'virus'].unique()[0]
            
            opto = obj['extraRewardTrials'].to_numpy()
            lasers = []
            for i in range(len(opto)):
                try:
                    lasers.append(int(opto[i][0]))
                except:
                    lasers.append(int(opto[i]))
        
            choices = list(obj['choice'].to_numpy())
            contrasts = list(obj['stimTrials'].to_numpy())
            rewards = list(obj['reward'].to_numpy())
            laser_side = list(obj['laser_side'].to_numpy())
        
            
            data = (rewards[:int(len(rewards)*train_set_size)],
                    contrasts[:int(len(rewards)*train_set_size)], 
                    choices[:int(len(rewards)*train_set_size)], 
                    lasers[:int(len(rewards)*train_set_size)])
            simulate_data = (rewards[:int(len(rewards)*train_set_size)], 
                             contrasts[:int(len(rewards)*train_set_size)], 
                             choices[:int(len(rewards)*train_set_size)], 
                          lasers[:int(len(rewards)*train_set_size)], 
                          laser_side[:int(len(rewards)*train_set_size)])
            
            if cross_validate == True:
                
                data = (rewards[:int(len(rewards)*train_set_size)],
                    contrasts[:int(len(rewards)*train_set_size)], 
                    choices[:int(len(rewards)*train_set_size)], 
                    lasers[:int(len(rewards)*train_set_size)])
                simulate_data_test = (rewards[int(len(rewards)*train_set_size):], 
                                      contrasts[int(len(rewards)*train_set_size):], 
                                      choices[int(len(rewards)*train_set_size):], 
                              lasers[int(len(rewards)*train_set_size):], 
                              laser_side[int(len(rewards)*train_set_size):])
            else:
                data_test = data
                simulate_data_test = simulate_data
            
    
            (best_x_stay, train_NLL_stay, buffer_NLL_stay, 
             buffer_x_stay) = optimizer_stay(data, initial_guess=[0.3, 0.05, -1, 0.2])
            
            cv_aic_stay = aic((session_neg_log_likelihood_stay(best_x_stay,
                      *data_test, pregen_all_posteriors=True))*-1,5)
            
           
            cv_LL_stay = (session_neg_log_likelihood_stay(best_x_stay, *data_test,
                                                          pregen_all_posteriors=True))*-1
           
            
            
            _, cv_acc_stay = session_neg_log_likelihood_stay(best_x_stay, *data_test, 
                           pregen_all_posteriors=True, accu=True)
           
            
            model_parameters_mouse = pd.DataFrame()
            model_parameters_mouse['x'] = [best_x_stay]
            model_parameters_mouse['LL'] = (cv_LL_stay/len(data_test[0]))
            model_parameters_mouse['aic'] = cv_aic_stay
            model_parameters_mouse['accu'] = cv_acc_stay
            model_parameters_mouse['model_name'] = 'w_stay'
    
            
            sim_data = generate_data_stay(simulate_data_test, all_contrasts, learning_rate=best_x_stay[0], 
                                           beliefSTD=best_x_stay[1], extraVal=best_x_stay[2], beta=best_x_stay[3])
            sim_data = pd.DataFrame(sim_data)
            
            sim_data = sim_data.rename(columns={0: "rewards", 1: "signed_contrast", 2: "simulated_choices", 3: "model_laser"})
            sim_data = np.array(sim_data)
            sim_data = pd.DataFrame(sim_data).T
            sim_data['laser'] = lasers[:int(len(rewards)*train_set_size)]
            sim_data['laser_side'] = laser_side[:int(len(rewards)*train_set_size)]
            sim_data['real_choice'] = choices[:int(len(rewards)*train_set_size)]
            sim_data['mouse_name']  = mouse
            sim_data['virus']  = virus
            sim_data['real_rewards']  = simulate_data[0]
           
            # Concatenate with general dataframes
            model_parameters_mouse['mouse'] = mouse
            model_parameters_mouse['virus'] = virus
            
            # Concatenate with general dataframes
            model_parameters = pd.concat([model_parameters, model_parameters_mouse])
            modelled_data = pd.concat([modelled_data, sim_data])
    
    return model_parameters


def model_w_stay_multiply_RPE():

    def true_stim_posterior(true_contrast, beliefSTD):
    	# Compute distribution over perceived contrast
    	# start_time = time.time()
    
    	def f(x):
    		return norm.cdf(x,0,beliefSTD) * norm.pdf(x,true_contrast,beliefSTD)
        
    	bs_right = quad(f,-np.inf, +np.inf)
    	return [1-bs_right[0],bs_right[0]]
    
    # Given all of the Q values (a matrix of size num_contrasts x 2), compute the overall Q_left and Q_right 
    # (i.e., the overall value of choosing left or right) given the perceived stimulus
    def compute_QL_QR(Q, trial_contrast, contrast_posterior):
    	Q_L = 0
    	Q_R = 0
    
    	# We compute Q_L, Q_R as in the Cell paper, by taking the weighted average of the various perceived stimuli,
    	# according to the probability that they were perceived
    	for i in range(len(contrast_posterior)):
    		Q_L += contrast_posterior[i] * Q[i, 0]
    		Q_R += contrast_posterior[i] * Q[i, 1]
    
    	return Q_L, Q_R
    
    def softmax_stay(Q_L, Q_R, beta, l_stay, r_stay, stay):
    	p = [np.exp(Q_L / beta + stay*l_stay),
          np.exp(Q_R / beta + stay*r_stay)]
    	p /= np.sum(p)
    
    	return p
    
    def trial_log_likelihood_stay(params, trial_data, Q, all_contrasts,
                                  all_posteriors, previous_trial, 
                                  trial_num, retrieve_Q = False, 
                                  retrieve_ITIQ = False):
    	# Get relevant parameters
    	trial_contrast, trial_choice, reward, laser = trial_data
    	learning_rate, beliefSTD, extraVal, beta, stay = params
    	Q =  Q.copy()
    
    	# Compute the log-likelihood of the actual mouse choice
    	if all_posteriors is None:
    		contrast_posterior = true_stim_posterior(trial_contrast, 
                                               beliefSTD)
    	else:
    		posterior_idx = np.argmin(np.abs(all_contrasts - trial_contrast))
    		contrast_posterior = all_posteriors[posterior_idx, :]
    
    	Q_L, Q_R = compute_QL_QR(Q, trial_contrast, contrast_posterior)
    	if trial_num == 0:
    		(l_stay, r_stay) = [0,0]
    	else:
    		previous_choice= [0,0]
    		previous_choice[previous_trial] = 1
    		(l_stay, r_stay) = previous_choice
        
    	choice_dist = softmax_stay(Q_L, Q_R, beta,l_stay, r_stay, stay)
    	LL = np.log(choice_dist[trial_choice])	
    
    	# Learning
    	if trial_choice == 0:
    		Q_chosen = Q_L
    	else:
    		Q_chosen = Q_R
    
    	# Update Q-values according to RPE modulated by laser
    	if laser == 1:
    		for i in range(2):
    			Q[i, trial_choice] += contrast_posterior[i] * \
                    learning_rate * ((reward - Q_chosen)*extraVal)
    	else:
    		for i in range(2):
    			Q[i, trial_choice] += contrast_posterior[i] * \
                    learning_rate * (reward - Q_chosen)
    
    	if retrieve_ITIQ == True:
    		Q_L = np.sum(Q, axis=0)[0]
    		Q_R = np.sum(Q, axis=0)[1]
    
    	if retrieve_Q==True:
    		return LL, Q, Q_L, Q_R, choice_dist[1] # choice_dist[1] = pChoice_right
        
    	else:
    		return LL, Q
    
    
    
    def session_neg_log_likelihood_stay(params, *data, pregen_all_posteriors=True, 
                                        accu=False, retrieve_Q =  False, retrieve_ITIQ = False):
    	# Unpack the arguments
    	learning_rate, beliefSTD, extraVal, beta, stay = params
    	rewards, true_contrasts, choices, lasers = data
    	num_trials = len(rewards)
        
    	if retrieve_Q==True:
    		Q_L = []
    		Q_R = []
    		pRight = []
    
    	# Generate the possible contrast list
    	all_contrasts = np.array([-0.25, -0.125, -0.0625, 0, 0.0625, 0.125, 0.25])
    	num_contrasts = len(all_contrasts)
    
    	# If True, generate all posterior distributions ahead of time to save time
    	if pregen_all_posteriors:
    		all_posteriors = np.zeros((num_contrasts, 2))
    		for idx, contrast in enumerate(all_contrasts):
    			all_posteriors[idx, :] = true_stim_posterior(contrast, beliefSTD)
    	else:
    		all_posteriors = None
    
    	# Compute the log-likelihood
    	if accu == True:
    		acc = 0
    	LL = 0
    	Q = np.zeros([2, 2])
        
    	if retrieve_Q == True:
                
    		for i in range(num_trials):
    			if i == 0:
    			    trial_LL, newQ, Q_Lt, Q_Rt, pright = trial_log_likelihood_stay(params, 
                                                [true_contrasts[i], choices[i], rewards[i], lasers[i]], 
                                                Q, all_contrasts, all_posteriors, 
                                                np.nan, i, retrieve_Q=retrieve_Q, retrieve_ITIQ=retrieve_ITIQ)
    			else:
    			    trial_LL, newQ, Q_Lt, Q_Rt, pright = trial_log_likelihood_stay(params, 
                                                [true_contrasts[i], choices[i], rewards[i], lasers[i]], 
                                                Q, all_contrasts, all_posteriors, 
                                                choices[i-1], i, retrieve_Q=retrieve_Q, retrieve_ITIQ=retrieve_ITIQ)
    
    			if (i != 0) & (np.sum(Q, axis=0)[0] != np.sum(newQ, axis=0)[0]) & (np.sum(Q, axis=0)[1] != np.sum(newQ, axis=0)[1]):
    				print('Warning, double update error in trial %d'%i)
    			LL += trial_LL
    			Q = newQ
                
    			if accu == True:
    				acc += (np.exp(trial_LL)>0.5)*1
                
    			Q_L.append(Q_Lt)
    			Q_R.append(Q_Rt)
    			pRight.append(pright)
            
    		
    	else:        
    		for i in range(num_trials):
    			if i == 0:
    			    trial_LL, newQ = trial_log_likelihood_stay(params, 
                                                [true_contrasts[i], choices[i], rewards[i], lasers[i]], 
                                                Q, all_contrasts, all_posteriors, np.nan, i)
    			else:
    			    trial_LL, newQ = trial_log_likelihood_stay(params, 
                                                [true_contrasts[i], choices[i], rewards[i], lasers[i]], 
                                                Q, all_contrasts, all_posteriors, choices[i-1], i)
    			LL += trial_LL
    			Q = newQ
                
    			if accu == True:
    				acc += (np.exp(trial_LL)>0.5)*1
                    
    
    	if retrieve_Q == True:   
    		if accu == True:
    			acc = acc/num_trials
    			return -LL,  acc, Q_L, Q_R, pRight
    		else:
    			return -LL, Q_L, Q_R, pRight
    
    	else:
    		if accu == True:
    			acc = acc/num_trials
    			return -LL,  acc
    		else:
    			return -LL
    
    
    
    
    
    # Optimize several times with different initializations and return the best fit parameters, and negative log likelihood
    
    def optimizer_stay(data, num_fits = 4, initial_guess=[0.1, 1, 0, 1, 1],
                       bound_type = 'chr2'):
    	# Accounting variables
    	best_NLL = np.Inf
    	best_x = [None, None, None, None, None]
    	buffer_NLL = []
    	buffer_x = np.empty([num_fits,len(initial_guess)])
    	# Do our fit with several different initializations
    	for i in range(num_fits):
    		print('Starting fit %d' % i)
    
    		# For every fit other than the first, construct a new initial guess
    		if i != 0:
    			lr_guess = np.random.uniform(0, 2)
    			beliefSTD_guess = np.random.uniform(0.03, 1)
    			if bound_type == 'chr2':
    				extraVal_guess = np.random.uniform(0.001,10)
    			else:
    				extraVal_guess = np.random.uniform(0.001,10)
    			beta_guess = np.random.uniform(0.01, 1)
    			stay = np.random.uniform(-1, 1)
    			initial_guess = [lr_guess, beliefSTD_guess, extraVal_guess, beta_guess, stay]
    
    		# Run the fit
    		if bound_type == 'chr2':
    			res = so.minimize(session_neg_log_likelihood_stay, initial_guess, args=data, 
                            method='L-BFGS-B', bounds=[(0, 2), (0.03, 1), (0.01, 10), (0.01, 1), 
                                            (-1,1)])
    		else:
    			res = so.minimize(session_neg_log_likelihood_stay, initial_guess, args=data, 
                            method='L-BFGS-B', bounds=[(0, 2), (0.03, 1), (0.01, 10), (0.01, 1), 
                                            (-1,1)])
    
    		# If this fit is better than the previous best, remember it, otherwise toss
    		buffer_x[i,:] = res.x
    		buffer_NLL.append(res.fun)
            
    		if res.fun <= best_NLL:
    			best_NLL = res.fun
    			best_x = res.x
    
    	return best_x, best_NLL, buffer_NLL, buffer_x
    
    
    
    # hardcode this for speed
    def normal_pdf(x, loc, scale):
    	factor = 1 / (np.sqrt(2 * np.pi) * scale)
    	power = -0.5 * (((x - loc) / scale) ** 2)
    
    	return factor * np.exp(power)
    
    ##### Analysis functions
    
    def accuracy_per_contrast(data, all_contrasts):
    	rewards, contrasts, choices, lasers = data
    	num_trials = len(rewards)
    
    	acc = np.zeros(len(all_contrasts))
    	trials_per_contrast = np.zeros(len(all_contrasts))
    	for i in range(num_trials):
    		reward = rewards[i]
    		contrast = contrasts[i]
    		choice = choices[i]
    		laser = lasers[i]
    
    		contrast_idx = np.argmin(np.abs(all_contrasts - contrast))
    		
    		if reward > 0:
    			acc[contrast_idx] += 1
    
    		trials_per_contrast[contrast_idx] += 1
    
    	acc /= trials_per_contrast
    
    	return acc
    
    def psychometric_curve(data, all_contrasts):
    	rewards, contrasts, choices, lasers = data
    	num_trials = len(rewards)
    
    	p_right = np.zeros(len(all_contrasts))
    	trials_per_contrast = np.zeros(len(all_contrasts))
    	for i in range(num_trials):
    		reward = rewards[i]
    		contrast = contrasts[i]
    		choice = choices[i]
    		laser = lasers[i]
    
    		contrast_idx = np.argmin(np.abs(all_contrasts - contrast))
    		
    		if choice == 1:
    			p_right[contrast_idx] += 1
    
    		trials_per_contrast[contrast_idx] += 1
    
    	p_right /= trials_per_contrast
    
    	return p_right
    
    ##### TESTING SCRIPT #####
    
    def simulation_contrast_distribution(mean_contrast, beliefSTD, all_contrasts):
    	# Compute distribution of final perceived contrasts
    	p = normal_pdf(all_contrasts, loc=mean_contrast, scale=beliefSTD)
    
    	# Renormalize
    	p /= np.sum(p)
    
    	return p
    
    
    def generate_data_stay(data, all_contrasts, learning_rate=0.3, 
                           beliefSTD=0.1, extraVal=1, beta=0.2, 
                           stay = 1, is_verbose=False, propagate_errors = True):
    	
    	rewards = []
    	true_contrasts = []
    	choices = []
    	lasers = []
        
    	if propagate_errors == False:
    		prop = 3
    	else:
    		prop = 4
    
    	# Simulate the POMDP model
    	Q = np.zeros([2, 2])
    	for t in range(len(data[0])):
    		if is_verbose:
    			print(t)
    
    		# Pick a true stimulus and store
    		trial_contrast = data[1][t]
    		true_contrasts.append(trial_contrast)
            # Add noise
    		perceived_contrast_distribution = simulation_contrast_distribution(trial_contrast, beliefSTD, all_contrasts)
    		perceived_contrast = np.random.choice(all_contrasts, p=perceived_contrast_distribution)
            
    		contrast_posterior = [0,0]
    		contrast_posterior[0] = norm.cdf(0, loc = trial_contrast, scale = beliefSTD)
    		contrast_posterior[1] = 1 - contrast_posterior[0]
            
    		Q_L, Q_R = compute_QL_QR(Q, perceived_contrast, contrast_posterior)
    
    		if t == 0:
    		    (l_stay, r_stay) = [0,0]
    		else:
    		    previous_choice= [0,0]
    		    previous_choice[choices[t-1]] = 1
    		    (l_stay, r_stay) = previous_choice
    		choice_dist = softmax_stay(Q_L, Q_R, beta,l_stay, r_stay, stay)
    		choice = np.random.choice(2, p = [float(choice_dist[0]), float(choice_dist[1])])
    		choices.append(choice)
    
    		# Get reward and store it
    		if np.sign(trial_contrast) == -1 and choice == 0:
    			reward = 1
    		elif np.sign(trial_contrast) == 1 and choice == 1:
    			reward = 1
    		elif np.sign(trial_contrast) == 0:
    			reward = random.choice([0,1])      
    		else:
    			reward = 0
    
    		rewards.append(reward)
    		
    		# Learn (update Q-values)
    		if choice == 0:
    			Q_chosen = Q_L
    		else:
    			Q_chosen = Q_R
            
    		contrast_posterior = [0,0]
    		contrast_posterior[0] = norm.cdf(0, loc = trial_contrast, scale = beliefSTD)
    		contrast_posterior[1] = 1 - contrast_posterior[0]
            
            # Add laser value on the correct condition
    		if propagate_errors == True:
    			if choice == data[prop][t]:
    			    for i in range(2):
            			Q[i, choice] += contrast_posterior[i] * learning_rate * (
                            (reward - Q_chosen)*extraVal)
    			    lasers.append(1)
    			else:
    			    for i in range(2):
            			Q[i, choice] += contrast_posterior[i] * learning_rate * \
                            (reward - Q_chosen)
    			    lasers.append(-1)
                    
    		else:
    			reward = data[0][t]
    			lasers.append(data[prop][t])
    			if data[prop][t] == 1:
    			    for i in range(2):
            			Q[i, choice] += contrast_posterior[i] * learning_rate \
                            * ((reward - Q_chosen)*extraVal)
    			else:
    					Q[i, choice] += contrast_posterior[i] * learning_rate * \
                            (reward - Q_chosen)                
    
    	return rewards, true_contrasts, choices, lasers
    
    def transform_model_struct_2_POMDP(model_data, simulate_data):
            simulate_data.loc[simulate_data['extraRewardTrials'] == 'right', 'extraRewardTrials' ] = 1
            simulate_data.loc[simulate_data['extraRewardTrials'] == 'left', 'extraRewardTrials' ] = 0
            simulate_data.loc[simulate_data['extraRewardTrials'] == 'none', 'extraRewardTrials' ] = -1
            obj = model_data
            obj['choice'] = obj['choice'] * -1
            obj.loc[obj['choice'] == -1, 'choice'] = 0
            obj['laser_side'] = simulate_data['extraRewardTrials']
            return obj
    
    def likelihood_ratio(llmin, llmax):
        return(2*(llmax-llmin))
    
    def aic(LL,n_param):
        # Calculates Akaike Information Criterion
        aic =  2*n_param - 2*LL
        return aic
        
    def chi2_LLR(L1,L2):
        LR = likelihood_ratio(L1,L2)
        p = chi2.sf(LR, 1) # L2 has 1 DoF more than L1
        return p

    mice = np.array(['dop_8', 'dop_9', 'dop_11', 'dop_4', 'dop_7'])
    
    # Load Alex's actual data
    psy = pd.read_pickle('all_behav.pkl')
    
    train_set_size = 1
    cross_validate = False
         
    all_contrasts = np.array([-0.25  , -0.125 , -0.0625,  0.    ,  0.0625, 0.125 , 0.25  ])
    best_nphr_individual = np.zeros([len(psy.loc[psy['virus'] == 'nphr', 'mouse_name'].unique()),4])
    best_nphr_NLL_individual = np.zeros([len(psy.loc[psy['virus'] == 'nphr', 'mouse_name'].unique()),1])
    model_parameters = pd.DataFrame()
    modelled_data = pd.DataFrame()
    
    for i, mouse in enumerate(mice): 
        model_data_nphr, simulate_data_nphr  = \
            psy_df_to_Q_learning_model_format(psy.loc[psy['mouse_name'] == mouse], 
            virus = psy.loc[psy['mouse_name'] == mouse, 'virus'].unique()[0])
        
        
        obj = transform_model_struct_2_POMDP(model_data_nphr, simulate_data_nphr)
        
        virus = psy.loc[psy['mouse_name'] == mouse, 'virus'].unique()[0]
        
        opto = obj['extraRewardTrials'].to_numpy()
        lasers = []
        for i in range(len(opto)):
            try:
                lasers.append(int(opto[i][0]))
            except:
                lasers.append(int(opto[i]))
    
        choices = list(obj['choice'].to_numpy())
        contrasts = list(obj['stimTrials'].to_numpy())
        rewards = list(obj['reward'].to_numpy())
        laser_side = list(obj['laser_side'].to_numpy())
    
        
        data = (rewards[:int(len(rewards)*train_set_size)],
                contrasts[:int(len(rewards)*train_set_size)], 
                choices[:int(len(rewards)*train_set_size)], 
                lasers[:int(len(rewards)*train_set_size)])
        simulate_data = (rewards[:int(len(rewards)*train_set_size)], 
                         contrasts[:int(len(rewards)*train_set_size)], 
                         choices[:int(len(rewards)*train_set_size)], 
                      lasers[:int(len(rewards)*train_set_size)], 
                      laser_side[:int(len(rewards)*train_set_size)])
        
        if cross_validate == True:
            
            data = (rewards[:int(len(rewards)*train_set_size)],
                contrasts[:int(len(rewards)*train_set_size)], 
                choices[:int(len(rewards)*train_set_size)], 
                lasers[:int(len(rewards)*train_set_size)])
            simulate_data_test = (rewards[int(len(rewards)*train_set_size):], 
                                  contrasts[int(len(rewards)*train_set_size):], 
                                  choices[int(len(rewards)*train_set_size):], 
                          lasers[int(len(rewards)*train_set_size):], 
                          laser_side[int(len(rewards)*train_set_size):])
        else:
            data_test = data
            simulate_data_test = simulate_data
        
        if virus == 'chr2':
            (best_x_stay, train_NLL_stay, buffer_NLL_stay, 
             buffer_x_stay) = optimizer_stay(data, initial_guess=[0.3, 0.05, 1, 0.2,1],
                                             bound_type =virus)
        
        if virus == 'nphr':
            (best_x_stay, train_NLL_stay, buffer_NLL_stay, 
             buffer_x_stay) = optimizer_stay(data, initial_guess=[0.3, 0.05, 1, 0.2,1],
                                             bound_type =virus)
        
        cv_aic_stay = aic((session_neg_log_likelihood_stay(best_x_stay,
                  *data_test, pregen_all_posteriors=True))*-1,5)
        
       
        cv_LL_stay = (session_neg_log_likelihood_stay(best_x_stay, *data_test,
                                                      pregen_all_posteriors=True))*-1
       
        
        
        _, cv_acc_stay = session_neg_log_likelihood_stay(best_x_stay, *data_test, 
                       pregen_all_posteriors=True, accu=True)
       
        
        model_parameters_mouse = pd.DataFrame()
        model_parameters_mouse['x'] = [best_x_stay]
        model_parameters_mouse['LL'] = (cv_LL_stay/len(data_test[0]))
        model_parameters_mouse['aic'] = cv_aic_stay
        model_parameters_mouse['accu'] = cv_acc_stay
        model_parameters_mouse['model_name'] = 'w_stay'

        
        sim_data = generate_data_stay(simulate_data_test, all_contrasts, learning_rate=best_x_stay[0], 
                                       beliefSTD=best_x_stay[1], extraVal=best_x_stay[2], beta=best_x_stay[3], stay=best_x_stay[4])
        sim_data = pd.DataFrame(sim_data)
        
        sim_data = sim_data.rename(columns={0: "rewards", 1: "signed_contrast", 2: "simulated_choices", 3: "model_laser"})
        sim_data = np.array(sim_data)
        sim_data = pd.DataFrame(sim_data).T
        sim_data['laser'] = lasers[:int(len(rewards)*train_set_size)]
        sim_data['laser_side'] = laser_side[:int(len(rewards)*train_set_size)]
        sim_data['real_choice'] = choices[:int(len(rewards)*train_set_size)]
        sim_data['mouse_name']  = mouse
        sim_data['virus']  = virus
        sim_data['real_rewards']  = simulate_data[0]
       
        # Concatenate with general dataframes
        model_parameters_mouse['mouse'] = mouse
        model_parameters_mouse['virus'] = virus
        
        # Concatenate with general dataframes
        model_parameters = pd.concat([model_parameters, model_parameters_mouse])
        modelled_data = pd.concat([modelled_data, sim_data])    
    
    return model_parameters


def model_wo_stay_multiply_RPE():

    def true_stim_posterior(true_contrast, beliefSTD):
    	# Compute distribution over perceived contrast
    	# start_time = time.time()
    
    	def f(x):
    		return norm.cdf(x,0,beliefSTD) * norm.pdf(x,true_contrast,beliefSTD)
        
    	bs_right = quad(f,-np.inf, +np.inf)
    	return [1-bs_right[0],bs_right[0]]
    
    # Given all of the Q values (a matrix of size num_contrasts x 2), compute the overall Q_left and Q_right 
    # (i.e., the overall value of choosing left or right) given the perceived stimulus
    def compute_QL_QR(Q, trial_contrast, contrast_posterior):
    	Q_L = 0
    	Q_R = 0
    
    	# We compute Q_L, Q_R as in the Cell paper, by taking the weighted average of the various perceived stimuli,
    	# according to the probability that they were perceived
    	for i in range(len(contrast_posterior)):
    		Q_L += contrast_posterior[i] * Q[i, 0]
    		Q_R += contrast_posterior[i] * Q[i, 1]
    
    	return Q_L, Q_R
    
    def softmax_stay(Q_L, Q_R, beta):
    	p = [np.exp(Q_L / beta),
          np.exp(Q_R / beta)]
    	p /= np.sum(p)
    
    	return p
    
    def trial_log_likelihood_stay(params, trial_data, Q, all_contrasts,
                                  all_posteriors, previous_trial, 
                                  trial_num, retrieve_Q = False, 
                                  retrieve_ITIQ = False):
    	# Get relevant parameters
    	trial_contrast, trial_choice, reward, laser = trial_data
    	learning_rate, beliefSTD, extraVal, beta = params
    	Q =  Q.copy()
    
    	# Compute the log-likelihood of the actual mouse choice
    	if all_posteriors is None:
    		contrast_posterior = true_stim_posterior(trial_contrast, 
                                               beliefSTD)
    	else:
    		posterior_idx = np.argmin(np.abs(all_contrasts - trial_contrast))
    		contrast_posterior = all_posteriors[posterior_idx, :]
    
    	Q_L, Q_R = compute_QL_QR(Q, trial_contrast, contrast_posterior)
    	
        
    	choice_dist = softmax_stay(Q_L, Q_R, beta)
    	LL = np.log(choice_dist[trial_choice])	
    
    	# Learning
    	if trial_choice == 0:
    		Q_chosen = Q_L
    	else:
    		Q_chosen = Q_R
    
    	# Update Q-values according to RPE modulated by laser
    	if laser == 1:
    		for i in range(2):
    			Q[i, trial_choice] += contrast_posterior[i] * \
                    learning_rate * ((reward - Q_chosen)*extraVal)
    	else:
    		for i in range(2):
    			Q[i, trial_choice] += contrast_posterior[i] * \
                    learning_rate * (reward - Q_chosen)
    
    	if retrieve_ITIQ == True:
    		Q_L = np.sum(Q, axis=0)[0]
    		Q_R = np.sum(Q, axis=0)[1]
    
    	if retrieve_Q==True:
    		return LL, Q, Q_L, Q_R, choice_dist[1] # choice_dist[1] = pChoice_right
        
    	else:
    		return LL, Q
    
    
    
    def session_neg_log_likelihood_stay(params, *data, pregen_all_posteriors=True, 
                                        accu=False, retrieve_Q =  False, retrieve_ITIQ = False):
    	# Unpack the arguments
    	learning_rate, beliefSTD, extraVal, beta = params
    	rewards, true_contrasts, choices, lasers = data
    	num_trials = len(rewards)
        
    	if retrieve_Q==True:
    		Q_L = []
    		Q_R = []
    		pRight = []
    
    	# Generate the possible contrast list
    	all_contrasts = np.array([-0.25, -0.125, -0.0625, 0, 0.0625, 0.125, 0.25])
    	num_contrasts = len(all_contrasts)
    
    	# If True, generate all posterior distributions ahead of time to save time
    	if pregen_all_posteriors:
    		all_posteriors = np.zeros((num_contrasts, 2))
    		for idx, contrast in enumerate(all_contrasts):
    			all_posteriors[idx, :] = true_stim_posterior(contrast, beliefSTD)
    	else:
    		all_posteriors = None
    
    	# Compute the log-likelihood
    	if accu == True:
    		acc = 0
    	LL = 0
    	Q = np.zeros([2, 2])
        
    	if retrieve_Q == True:
                
    		for i in range(num_trials):
    			if i == 0:
    			    trial_LL, newQ, Q_Lt, Q_Rt, pright = trial_log_likelihood_stay(params, 
                                                [true_contrasts[i], choices[i], rewards[i], lasers[i]], 
                                                Q, all_contrasts, all_posteriors, 
                                                np.nan, i, retrieve_Q=retrieve_Q, retrieve_ITIQ=retrieve_ITIQ)
    			else:
    			    trial_LL, newQ, Q_Lt, Q_Rt, pright = trial_log_likelihood_stay(params, 
                                                [true_contrasts[i], choices[i], rewards[i], lasers[i]], 
                                                Q, all_contrasts, all_posteriors, 
                                                choices[i-1], i, retrieve_Q=retrieve_Q, retrieve_ITIQ=retrieve_ITIQ)
    
    			if (i != 0) & (np.sum(Q, axis=0)[0] != np.sum(newQ, axis=0)[0]) & (np.sum(Q, axis=0)[1] != np.sum(newQ, axis=0)[1]):
    				print('Warning, double update error in trial %d'%i)
    			LL += trial_LL
    			Q = newQ
                
    			if accu == True:
    				acc += (np.exp(trial_LL)>0.5)*1
                
    			Q_L.append(Q_Lt)
    			Q_R.append(Q_Rt)
    			pRight.append(pright)
            
    		
    	else:        
    		for i in range(num_trials):
    			if i == 0:
    			    trial_LL, newQ = trial_log_likelihood_stay(params, 
                                                [true_contrasts[i], choices[i], rewards[i], lasers[i]], 
                                                Q, all_contrasts, all_posteriors, np.nan, i)
    			else:
    			    trial_LL, newQ = trial_log_likelihood_stay(params, 
                                                [true_contrasts[i], choices[i], rewards[i], lasers[i]], 
                                                Q, all_contrasts, all_posteriors, choices[i-1], i)
    			LL += trial_LL
    			Q = newQ
                
    			if accu == True:
    				acc += (np.exp(trial_LL)>0.5)*1
                    
    
    	if retrieve_Q == True:   
    		if accu == True:
    			acc = acc/num_trials
    			return -LL,  acc, Q_L, Q_R, pRight
    		else:
    			return -LL, Q_L, Q_R, pRight
    
    	else:
    		if accu == True:
    			acc = acc/num_trials
    			return -LL,  acc
    		else:
    			return -LL
    
    
    
    
    
    # Optimize several times with different initializations and return the best fit parameters, and negative log likelihood
    
    def optimizer_stay(data, num_fits = 4, initial_guess=[0.1, 1, 0, 1],
                       bound_type = 'chr2'):
    	# Accounting variables
    	best_NLL = np.Inf
    	best_x = [None, None, None, None]
    	buffer_NLL = []
    	buffer_x = np.empty([num_fits,len(initial_guess)])
    	# Do our fit with several different initializations
    	for i in range(num_fits):
    		print('Starting fit %d' % i)
    
    		# For every fit other than the first, construct a new initial guess
    		if i != 0:
    			lr_guess = np.random.uniform(0, 2)
    			beliefSTD_guess = np.random.uniform(0.03, 1)
    			if bound_type == 'chr2':
    				extraVal_guess = np.random.uniform(0.001,10)
    			else:
    				extraVal_guess = np.random.uniform(0.001,10)
    			beta_guess = np.random.uniform(0.01, 1)
    			initial_guess = [lr_guess, beliefSTD_guess, extraVal_guess, beta_guess]
    
    		# Run the fit
    		if bound_type == 'chr2':
    			res = so.minimize(session_neg_log_likelihood_stay, initial_guess, args=data, 
                            method='L-BFGS-B', bounds=[(0, 2), (0.03, 1), (0.01, 10), (0.01, 1)])
    		else:
    			res = so.minimize(session_neg_log_likelihood_stay, initial_guess, args=data, 
                            method='L-BFGS-B', bounds=[(0, 2), (0.03, 1), (0.01, 10), (0.01, 1)])
    
    		# If this fit is better than the previous best, remember it, otherwise toss
    		buffer_x[i,:] = res.x
    		buffer_NLL.append(res.fun)
            
    		if res.fun <= best_NLL:
    			best_NLL = res.fun
    			best_x = res.x
    
    	return best_x, best_NLL, buffer_NLL, buffer_x
    
    
    
    # hardcode this for speed
    def normal_pdf(x, loc, scale):
    	factor = 1 / (np.sqrt(2 * np.pi) * scale)
    	power = -0.5 * (((x - loc) / scale) ** 2)
    
    	return factor * np.exp(power)
    
    ##### Analysis functions
    
    def accuracy_per_contrast(data, all_contrasts):
    	rewards, contrasts, choices, lasers = data
    	num_trials = len(rewards)
    
    	acc = np.zeros(len(all_contrasts))
    	trials_per_contrast = np.zeros(len(all_contrasts))
    	for i in range(num_trials):
    		reward = rewards[i]
    		contrast = contrasts[i]
    		choice = choices[i]
    		laser = lasers[i]
    
    		contrast_idx = np.argmin(np.abs(all_contrasts - contrast))
    		
    		if reward > 0:
    			acc[contrast_idx] += 1
    
    		trials_per_contrast[contrast_idx] += 1
    
    	acc /= trials_per_contrast
    
    	return acc
    
    def psychometric_curve(data, all_contrasts):
    	rewards, contrasts, choices, lasers = data
    	num_trials = len(rewards)
    
    	p_right = np.zeros(len(all_contrasts))
    	trials_per_contrast = np.zeros(len(all_contrasts))
    	for i in range(num_trials):
    		reward = rewards[i]
    		contrast = contrasts[i]
    		choice = choices[i]
    		laser = lasers[i]
    
    		contrast_idx = np.argmin(np.abs(all_contrasts - contrast))
    		
    		if choice == 1:
    			p_right[contrast_idx] += 1
    
    		trials_per_contrast[contrast_idx] += 1
    
    	p_right /= trials_per_contrast
    
    	return p_right
    
    ##### TESTING SCRIPT #####
    
    def simulation_contrast_distribution(mean_contrast, beliefSTD, all_contrasts):
    	# Compute distribution of final perceived contrasts
    	p = normal_pdf(all_contrasts, loc=mean_contrast, scale=beliefSTD)
    
    	# Renormalize
    	p /= np.sum(p)
    
    	return p
    
    
    def generate_data_stay(data, all_contrasts, learning_rate=0.3, 
                           beliefSTD=0.1, extraVal=1, beta=0.2, 
                           is_verbose=False, propagate_errors = True):
    	
    	rewards = []
    	true_contrasts = []
    	choices = []
    	lasers = []
        
    	if propagate_errors == False:
    		prop = 3
    	else:
    		prop = 4
    
    	# Simulate the POMDP model
    	Q = np.zeros([2, 2])
    	for t in range(len(data[0])):
    		if is_verbose:
    			print(t)
    
    		# Pick a true stimulus and store
    		trial_contrast = data[1][t]
    		true_contrasts.append(trial_contrast)
            # Add noise
    		perceived_contrast_distribution = simulation_contrast_distribution(trial_contrast, beliefSTD, all_contrasts)
    		perceived_contrast = np.random.choice(all_contrasts, p=perceived_contrast_distribution)
            
    		contrast_posterior = [0,0]
    		contrast_posterior[0] = norm.cdf(0, loc = trial_contrast, scale = beliefSTD)
    		contrast_posterior[1] = 1 - contrast_posterior[0]
            
    		Q_L, Q_R = compute_QL_QR(Q, perceived_contrast, contrast_posterior)
    
    		
    		choice_dist = softmax_stay(Q_L, Q_R, beta)
    		choice = np.random.choice(2, p = [float(choice_dist[0]), float(choice_dist[1])])
    		choices.append(choice)
    
    		# Get reward and store it
    		if np.sign(trial_contrast) == -1 and choice == 0:
    			reward = 1
    		elif np.sign(trial_contrast) == 1 and choice == 1:
    			reward = 1
    		elif np.sign(trial_contrast) == 0:
    			reward = random.choice([0,1])      
    		else:
    			reward = 0
    
    		rewards.append(reward)
    		
    		# Learn (update Q-values)
    		if choice == 0:
    			Q_chosen = Q_L
    		else:
    			Q_chosen = Q_R
            
    		contrast_posterior = [0,0]
    		contrast_posterior[0] = norm.cdf(0, loc = trial_contrast, scale = beliefSTD)
    		contrast_posterior[1] = 1 - contrast_posterior[0]
            
            # Add laser value on the correct condition
    		if propagate_errors == True:
    			if choice == data[prop][t]:
    			    for i in range(2):
            			Q[i, choice] += contrast_posterior[i] * learning_rate * (
                            (reward - Q_chosen)*extraVal)
    			    lasers.append(1)
    			else:
    			    for i in range(2):
            			Q[i, choice] += contrast_posterior[i] * learning_rate * \
                            (reward - Q_chosen)
    			    lasers.append(-1)
                    
    		else:
    			reward = data[0][t]
    			lasers.append(data[prop][t])
    			if data[prop][t] == 1:
    			    for i in range(2):
            			Q[i, choice] += contrast_posterior[i] * learning_rate \
                            * ((reward - Q_chosen)*extraVal)
    			else:
    					Q[i, choice] += contrast_posterior[i] * learning_rate * \
                            (reward - Q_chosen)                
    
    	return rewards, true_contrasts, choices, lasers
    
    def transform_model_struct_2_POMDP(model_data, simulate_data):
            simulate_data.loc[simulate_data['extraRewardTrials'] == 'right', 'extraRewardTrials' ] = 1
            simulate_data.loc[simulate_data['extraRewardTrials'] == 'left', 'extraRewardTrials' ] = 0
            simulate_data.loc[simulate_data['extraRewardTrials'] == 'none', 'extraRewardTrials' ] = -1
            obj = model_data
            obj['choice'] = obj['choice'] * -1
            obj.loc[obj['choice'] == -1, 'choice'] = 0
            obj['laser_side'] = simulate_data['extraRewardTrials']
            return obj
    
    def likelihood_ratio(llmin, llmax):
        return(2*(llmax-llmin))
    
    def aic(LL,n_param):
        # Calculates Akaike Information Criterion
        aic =  2*n_param - 2*LL
        return aic
        
    def chi2_LLR(L1,L2):
        LR = likelihood_ratio(L1,L2)
        p = chi2.sf(LR, 1) # L2 has 1 DoF more than L1
        return p

    mice = np.array(['dop_8', 'dop_9', 'dop_11', 'dop_4', 'dop_7'])
    
    # Load Alex's actual data
    psy = pd.read_pickle('all_behav.pkl')
    
    train_set_size = 1
    cross_validate = False
         
    all_contrasts = np.array([-0.25  , -0.125 , -0.0625,  0.    ,  0.0625, 0.125 , 0.25  ])
    best_nphr_individual = np.zeros([len(psy.loc[psy['virus'] == 'nphr', 'mouse_name'].unique()),4])
    best_nphr_NLL_individual = np.zeros([len(psy.loc[psy['virus'] == 'nphr', 'mouse_name'].unique()),1])
    model_parameters = pd.DataFrame()
    modelled_data = pd.DataFrame()
    for i, mouse in enumerate(mice): 
            model_data_nphr, simulate_data_nphr  = \
                psy_df_to_Q_learning_model_format(psy.loc[psy['mouse_name'] == mouse], 
                                                  virus = psy.loc[psy['mouse_name'] == mouse, 'virus'].unique()[0])
            
            
            obj = transform_model_struct_2_POMDP(model_data_nphr, simulate_data_nphr)
            
            virus = psy.loc[psy['mouse_name'] == mouse, 'virus'].unique()[0]
            
            opto = obj['extraRewardTrials'].to_numpy()
            lasers = []
            for i in range(len(opto)):
                try:
                    lasers.append(int(opto[i][0]))
                except:
                    lasers.append(int(opto[i]))
        
            choices = list(obj['choice'].to_numpy())
            contrasts = list(obj['stimTrials'].to_numpy())
            rewards = list(obj['reward'].to_numpy())
            laser_side = list(obj['laser_side'].to_numpy())
        
            
            data = (rewards[:int(len(rewards)*train_set_size)],
                    contrasts[:int(len(rewards)*train_set_size)], 
                    choices[:int(len(rewards)*train_set_size)], 
                    lasers[:int(len(rewards)*train_set_size)])
            simulate_data = (rewards[:int(len(rewards)*train_set_size)], 
                             contrasts[:int(len(rewards)*train_set_size)], 
                             choices[:int(len(rewards)*train_set_size)], 
                          lasers[:int(len(rewards)*train_set_size)], 
                          laser_side[:int(len(rewards)*train_set_size)])
            
            if cross_validate == True:
                
                data = (rewards[:int(len(rewards)*train_set_size)],
                    contrasts[:int(len(rewards)*train_set_size)], 
                    choices[:int(len(rewards)*train_set_size)], 
                    lasers[:int(len(rewards)*train_set_size)])
                simulate_data_test = (rewards[int(len(rewards)*train_set_size):], 
                                      contrasts[int(len(rewards)*train_set_size):], 
                                      choices[int(len(rewards)*train_set_size):], 
                              lasers[int(len(rewards)*train_set_size):], 
                              laser_side[int(len(rewards)*train_set_size):])
            else:
                data_test = data
                simulate_data_test = simulate_data
            
    
            if virus == 'chr2':
                (best_x_stay, train_NLL_stay, buffer_NLL_stay, 
                buffer_x_stay) = optimizer_stay(data, initial_guess=[0.3, 0.05, 1, 0.2],
                                             bound_type =virus)
        
            if virus == 'nphr':
                (best_x_stay, train_NLL_stay, buffer_NLL_stay, 
                buffer_x_stay) = optimizer_stay(data, initial_guess=[0.3, 0.05, 1, 0.2],
                                             bound_type =virus)
            
            cv_aic_stay = aic((session_neg_log_likelihood_stay(best_x_stay,
                      *data_test, pregen_all_posteriors=True))*-1,5)
            
           
            cv_LL_stay = (session_neg_log_likelihood_stay(best_x_stay, *data_test,
                                                          pregen_all_posteriors=True))*-1
           
            
            
            _, cv_acc_stay = session_neg_log_likelihood_stay(best_x_stay, *data_test, 
                           pregen_all_posteriors=True, accu=True)
           
            
            model_parameters_mouse = pd.DataFrame()
            model_parameters_mouse['x'] = [best_x_stay]
            model_parameters_mouse['LL'] = (cv_LL_stay/len(data_test[0]))
            model_parameters_mouse['aic'] = cv_aic_stay
            model_parameters_mouse['accu'] = cv_acc_stay
            model_parameters_mouse['model_name'] = 'w_stay'
    
            
            sim_data = generate_data_stay(simulate_data_test, all_contrasts, learning_rate=best_x_stay[0], 
                                           beliefSTD=best_x_stay[1], extraVal=best_x_stay[2], beta=best_x_stay[3])
            sim_data = pd.DataFrame(sim_data)
            
            sim_data = sim_data.rename(columns={0: "rewards", 1: "signed_contrast", 2: "simulated_choices", 3: "model_laser"})
            sim_data = np.array(sim_data)
            sim_data = pd.DataFrame(sim_data).T
            sim_data['laser'] = lasers[:int(len(rewards)*train_set_size)]
            sim_data['laser_side'] = laser_side[:int(len(rewards)*train_set_size)]
            sim_data['real_choice'] = choices[:int(len(rewards)*train_set_size)]
            sim_data['mouse_name']  = mouse
            sim_data['virus']  = virus
            sim_data['real_rewards']  = simulate_data[0]
           
            # Concatenate with general dataframes
            model_parameters_mouse['mouse'] = mouse
            model_parameters_mouse['virus'] = virus
            
            # Concatenate with general dataframes
            model_parameters = pd.concat([model_parameters, model_parameters_mouse])
            modelled_data = pd.concat([modelled_data, sim_data])
    
    return model_parameters

def model_2_laser_w_stay():
    
    def true_stim_posterior(true_contrast, beliefSTD):
    	# Compute distribution over perceived contrast
    	# start_time = time.time()
    
    	def f(x):
    		return norm.cdf(x,0,beliefSTD) * norm.pdf(x,true_contrast,beliefSTD)
        
    	bs_right = quad(f,-np.inf, +np.inf)
    	return [1-bs_right[0],bs_right[0]]
    

    # Given all of the Q values (a matrix of size num_contrasts x 2), compute the overall Q_left and Q_right 
    # (i.e., the overall value of choosing left or right) given the perceived stimulus
    def compute_QL_QR(Q, trial_contrast, contrast_posterior):
    	Q_L = 0
    	Q_R = 0
    
    	# We compute Q_L, Q_R as in the Cell paper, by taking the weighted average of the various perceived stimuli,
    	# according to the probability that they were perceived
    	for i in range(len(contrast_posterior)):
    		Q_L += contrast_posterior[i] * Q[i, 0]
    		Q_R += contrast_posterior[i] * Q[i, 1]
    
    	return Q_L, Q_R
    
    def softmax_stay(Q_L, Q_R, beta, l_stay, r_stay, stay):
    	p = [np.exp(Q_L / beta + stay*l_stay),
          np.exp(Q_R / beta + stay*r_stay)]
    	p /= np.sum(p)
    
    	return p
    
    def trial_log_likelihood_stay(params, trial_data, Q, all_contrasts, all_posteriors, 
                                  previous_trial, trial_num, retrieve_Q = False):
    	# Get relevant parameters
    	trial_contrast, trial_choice, reward, laser = trial_data
    	learning_rate, beliefSTD, extraVal, beta, stay, extraVal_nowater_guess = params
    	extraVal_nowater_guess = extraVal
        
    
    	# Compute the log-likelihood of the actual mouse choice
    	if all_posteriors is None:
    		contrast_posterior = true_stim_posterior(trial_contrast, beliefSTD)
    	else:
    		posterior_idx = np.argmin(np.abs(all_contrasts - trial_contrast))
    		contrast_posterior = all_posteriors[posterior_idx, :]
    
    	Q_L, Q_R = compute_QL_QR(Q, trial_contrast, contrast_posterior)
    	if trial_num == 0:
    		(l_stay, r_stay) = [0,0]
    	else:
    		previous_choice= [0,0]
    		previous_choice[previous_trial] = 1
    		(l_stay, r_stay) = previous_choice
        
    	choice_dist = softmax_stay(Q_L, Q_R, beta,l_stay, r_stay, stay)
    	LL = np.log(choice_dist[trial_choice])	
    
    	# Learning
    	if trial_choice == 0:
    		Q_chosen = Q_L
    	else:
    		Q_chosen = Q_R
    
    	# Laser-modulation
    	if laser == 1:
    		if reward ==1:
    			received_reward = reward + extraVal
    		else:
    			received_reward = extraVal_nowater_guess
    	else:
    		received_reward = reward
    
    	# Update Q-values according to the aggregate reward + laser value
    	for i in range(2):
    		Q[i, trial_choice] += contrast_posterior[i] * learning_rate * (received_reward - Q_chosen)
    
    	if retrieve_Q==True:
    		return LL, Q, Q_L, Q_R, choice_dist[1] #  choice_dist[1] = pChoice_right
    	else:
    		return LL, Q
    
    
    
    def session_neg_log_likelihood_stay(params, *data, pregen_all_posteriors=True, accu=False, retrieve_Q =  False):
    	# Unpack the arguments
    	learning_rate, beliefSTD, extraVal, beta, stay, extraVal_nowater_guess = params
    	rewards, true_contrasts, choices, lasers = data
    	num_trials = len(rewards)
        
    	if retrieve_Q==True:
    		Q_L = []
    		Q_R = []
    		pRight = []
    
    	# Generate the possible contrast list
    	all_contrasts = np.array([-0.25, -0.125, -0.6125, 0, 0.6125, 0.125, 0.25])
    	num_contrasts = len(all_contrasts)
    
    	# If True, generate all posterior distributions ahead of time to save time
    	if pregen_all_posteriors:
    		all_posteriors = np.zeros((num_contrasts, 2))
    		for idx, contrast in enumerate(all_contrasts):
    			all_posteriors[idx, :] = true_stim_posterior(contrast, beliefSTD)
    	else:
    		all_posteriors = None
    
    	# Compute the log-likelihood
    	if accu == True:
    		acc = 0
    	LL = 0
    	Q = np.zeros([2, 2])
        
    	if retrieve_Q == True:
                
    		for i in range(num_trials):
    			if i == 0:
    			    trial_LL, newQ, Q_Lt, Q_Rt, pright = trial_log_likelihood_stay(params, 
                                                [true_contrasts[i], choices[i], rewards[i], lasers[i]], 
                                                Q, all_contrasts, all_posteriors, np.nan, i, retrieve_Q=retrieve_Q)
    			else:
    			    trial_LL, newQ, Q_Lt, Q_Rt, pright = trial_log_likelihood_stay(params, 
                                                [true_contrasts[i], choices[i], rewards[i], lasers[i]], 
                                                Q, all_contrasts, all_posteriors, choices[i-1], i, retrieve_Q=retrieve_Q)
    			LL += trial_LL
    			Q = newQ
                
    			if accu == True:
    				acc += (np.exp(trial_LL)>0.5)*1
                
    			Q_L.append(Q_Lt)
    			Q_R.append(Q_Rt)
    			pRight.append(pright)
            
    		
    	else:        
    		for i in range(num_trials):
    			if i == 0:
    			    trial_LL, newQ = trial_log_likelihood_stay(params, 
                                                [true_contrasts[i], choices[i], rewards[i], lasers[i]], 
                                                Q, all_contrasts, all_posteriors, np.nan, i)
    			else:
    			    trial_LL, newQ = trial_log_likelihood_stay(params, 
                                                [true_contrasts[i], choices[i], rewards[i], lasers[i]], 
                                                Q, all_contrasts, all_posteriors, choices[i-1], i)
    			LL += trial_LL
    			Q = newQ
                
    			if accu == True:
    				acc += (np.exp(trial_LL)>0.5)*1
                    
    
    	if retrieve_Q == True:   
    		if accu == True:
    			acc = acc/num_trials
    			return -LL,  acc, Q_L, Q_R, pRight
    		else:
    			return -LL, Q_L, Q_R, pRight
    
    	else:
    		if accu == True:
    			acc = acc/num_trials
    			return -LL,  acc
    		else:
    			return -LL
    
    
    
    
    
    # Optimize several times with different initializations and return the best fit parameters, and negative log likelihood
    
    def optimizer_stay(data, num_fits = 4, initial_guess=[0.1, 1, 0, 1, 1,0]):
    	# Accounting variables
    	best_NLL = np.Inf
    	best_x = [None, None, None, None, None]
    	buffer_NLL = []
    	buffer_x = np.empty([num_fits,len(initial_guess)])
    	# Do our fit with several different initializations
    	for i in range(num_fits):
    		print('Starting fit %d' % i)
    
    		# For every fit other than the first, construct a new initial guess
    		if i != 0:
    			lr_guess = np.random.uniform(0, 2)
    			beliefSTD_guess = np.random.uniform(0.03, 1)
    			extraVal_guess = np.random.uniform(-2,2)
    			beta_guess = np.random.uniform(0.01, 1)
    			stay = np.random.uniform(-1, 1)
    			extraVal_nowater_guess = np.random.uniform(-2,2)
    			initial_guess = [lr_guess, beliefSTD_guess, extraVal_guess, beta_guess, stay, extraVal_nowater_guess]
    
    		# Run the fit
    		res = so.minimize(session_neg_log_likelihood_stay, initial_guess, args=data, 
                        method='L-BFGS-B', bounds=[(0, 2), (0.03, 1), (-2, 2), (0.01, 1), 
                                        (-1,1), (-2, 2)])
    
    		# If this fit is better than the previous best, remember it, otherwise toss
    		buffer_x[i,:] = res.x
    		buffer_NLL.append(res.fun)
            
    		if res.fun <= best_NLL:
    			best_NLL = res.fun
    			best_x = res.x
    
    	return best_x, best_NLL, buffer_NLL, buffer_x
    
    
    
    # hardcode this for speed
    def normal_pdf(x, loc, scale):
    	factor = 1 / (np.sqrt(2 * np.pi) * scale)
    	power = -0.5 * (((x - loc) / scale) ** 2)
    
    	return factor * np.exp(power)
    
    ##### Analysis functions
    
    def accuracy_per_contrast(data, all_contrasts):
    	rewards, contrasts, choices, lasers = data
    	num_trials = len(rewards)
    
    	acc = np.zeros(len(all_contrasts))
    	trials_per_contrast = np.zeros(len(all_contrasts))
    	for i in range(num_trials):
    		reward = rewards[i]
    		contrast = contrasts[i]
    		choice = choices[i]
    		laser = lasers[i]
    
    		contrast_idx = np.argmin(np.abs(all_contrasts - contrast))
    		
    		if reward > 0:
    			acc[contrast_idx] += 1
    
    		trials_per_contrast[contrast_idx] += 1
    
    	acc /= trials_per_contrast
    
    	return acc
    
    def psychometric_curve(data, all_contrasts):
    	rewards, contrasts, choices, lasers = data
    	num_trials = len(rewards)
    
    	p_right = np.zeros(len(all_contrasts))
    	trials_per_contrast = np.zeros(len(all_contrasts))
    	for i in range(num_trials):
    		reward = rewards[i]
    		contrast = contrasts[i]
    		choice = choices[i]
    		laser = lasers[i]
    
    		contrast_idx = np.argmin(np.abs(all_contrasts - contrast))
    		
    		if choice == 1:
    			p_right[contrast_idx] += 1
    
    		trials_per_contrast[contrast_idx] += 1
    
    	p_right /= trials_per_contrast
    
    	return p_right
    
    ##### TESTING SCRIPT #####
    
    def simulation_contrast_distribution(mean_contrast, beliefSTD, all_contrasts):
    	# Compute distribution of final perceived contrasts
    	p = normal_pdf(all_contrasts, loc=mean_contrast, scale=beliefSTD)
    
    	# Renormalize
    	p /= np.sum(p)
    
    	return p
    
    
    def generate_data_stay(data, all_contrasts, learning_rate=0.3, 
                           beliefSTD=0.1, extraVal=1, beta=0.2, 
                           stay = 1, extraVal_nowater = 1, is_verbose=False, 
                           propagate_errors = True):
        
    	rewards = []
    	true_contrasts = []
    	choices = []
    	lasers = []
        
    	if propagate_errors == False:
    		prop = 3
    	else:
    		prop = 4
    
    	# Simulate the POMDP model
    	Q = np.zeros([2, 2])
    	for t in range(len(data[0])):
    		if is_verbose:
    			print(t)
    
    		# Pick a true stimulus and store
    		trial_contrast = data[1][t]
    		true_contrasts.append(trial_contrast)
            # Add noise
    		perceived_contrast_distribution = simulation_contrast_distribution(trial_contrast, beliefSTD, all_contrasts)
    		perceived_contrast = np.random.choice(all_contrasts, p=perceived_contrast_distribution)
            
    		contrast_posterior = [0,0]
    		contrast_posterior[0] = norm.cdf(0, loc = perceived_contrast, scale = beliefSTD)
    		contrast_posterior[1] = 1 - contrast_posterior[0]
            
    		Q_L, Q_R = compute_QL_QR(Q, perceived_contrast, contrast_posterior)
    
    		if t == 0:
    		    (l_stay, r_stay) = [0,0]
    		else:
    		    previous_choice= [0,0]
    		    previous_choice[choices[t-1]] = 1
    		    (l_stay, r_stay) = previous_choice
    		choice_dist = softmax_stay(Q_L, Q_R, beta,l_stay, r_stay, stay)
    		choice = np.random.choice(2, p = [float(choice_dist[0]), float(choice_dist[1])])
    		choices.append(choice)
    
    		# Get reward and store it
    		if np.sign(trial_contrast) == -1 and choice == 0:
    			reward = 1
    		elif np.sign(trial_contrast) == 1 and choice == 1:
    			reward = 1
    		elif np.sign(trial_contrast) == 0:
    			reward = random.choice([0,1])      
    		else:
    			reward = 0
    
    		rewards.append(reward)
    		
    		# Add laser value on the correct condition
    		if propagate_errors == True:
    			if choice == data[prop][t]:
    			    reward += extraVal
    			    lasers.append(1)
    			else:
    			    lasers.append(-1)
    		else:
    			reward = data[0][t]
    			if reward == 0:
    			    reward = extraVal_nowater
    			else:
    			    reward += extraVal*data[prop][t]
    			    lasers.append(data[prop][t])
    		# Learn (update Q-values)
    		if choice == 0:
    			Q_chosen = Q_L
    		else:
    			Q_chosen = Q_R
            
    		contrast_posterior = [0,0]
    		contrast_posterior[0] = norm.cdf(0, loc = perceived_contrast, scale = beliefSTD)
    		contrast_posterior[1] = 1 - contrast_posterior[0]
    
    		for i in range(2):
    			Q[i, choice] += contrast_posterior[i] * learning_rate * (reward - Q_chosen)
    
    	return rewards, true_contrasts, choices, lasers
    
    def transform_model_struct_2_POMDP(model_data, simulate_data):
            simulate_data.loc[simulate_data['extraRewardTrials'] == 'right', 'extraRewardTrials' ] = 1
            simulate_data.loc[simulate_data['extraRewardTrials'] == 'left', 'extraRewardTrials' ] = 0
            simulate_data.loc[simulate_data['extraRewardTrials'] == 'none', 'extraRewardTrials' ] = -1
            obj = model_data
            obj['choice'] = obj['choice'] * -1
            obj.loc[obj['choice'] == -1, 'choice'] = 0
            obj['laser_side'] = simulate_data['extraRewardTrials']
            return obj
    
    def likelihood_ratio(llmin, llmax):
        return(2*(llmax-llmin))
    
    def aic(LL,n_param):
        # Calculates Akaike Information Criterion
        aic =  2*n_param - 2*LL
        return aic
        
    def chi2_LLR(L1,L2):
        LR = likelihood_ratio(L1,L2)
        p = chi2.sf(LR, 1) # L2 has 1 DoF more than L1
        return p
        

	# print(x)
    mice = np.array(['dop_8', 'dop_9', 'dop_11', 'dop_4', 'dop_7'])

	# Load Alex's actual data
    psy = pd.read_pickle('all_behav.pkl')

    train_set_size = 1
    cross_validate = False
     
    all_contrasts = np.array([-0.25  , -0.125 , -0.0625,  0.    ,  0.0625, 0.125 , 0.25  ])
    best_nphr_individual = np.zeros([len(psy.loc[psy['virus'] == 'nphr', 'mouse_name'].unique()),4])
    best_nphr_NLL_individual = np.zeros([len(psy.loc[psy['virus'] == 'nphr', 'mouse_name'].unique()),1])
    model_parameters = pd.DataFrame()
    modelled_data = pd.DataFrame()
    for i, mouse in enumerate(mice): 
        model_data_nphr, simulate_data_nphr  = \
            psy_df_to_Q_learning_model_format(psy.loc[psy['mouse_name'] == mouse], 
                                              virus = psy.loc[psy['mouse_name'] == mouse, 'virus'].unique()[0])
        
        
        obj = transform_model_struct_2_POMDP(model_data_nphr, simulate_data_nphr)
        
        virus = psy.loc[psy['mouse_name'] == mouse, 'virus'].unique()[0]
        
        opto = obj['extraRewardTrials'].to_numpy()
        lasers = []
        for i in range(len(opto)):
            try:
                lasers.append(int(opto[i][0]))
            except:
                lasers.append(int(opto[i]))
    
        choices = list(obj['choice'].to_numpy())
        contrasts = list(obj['stimTrials'].to_numpy())
        rewards = list(obj['reward'].to_numpy())
        laser_side = list(obj['laser_side'].to_numpy())
    
        
        data = (rewards[:int(len(rewards)*train_set_size)],
                contrasts[:int(len(rewards)*train_set_size)], 
                choices[:int(len(rewards)*train_set_size)], 
                lasers[:int(len(rewards)*train_set_size)])
        simulate_data = (rewards[:int(len(rewards)*train_set_size)], 
                         contrasts[:int(len(rewards)*train_set_size)], 
                         choices[:int(len(rewards)*train_set_size)], 
                      lasers[:int(len(rewards)*train_set_size)], 
                      laser_side[:int(len(rewards)*train_set_size)])
        
        if cross_validate == True:
            
            data = (rewards[:int(len(rewards)*train_set_size)],
                contrasts[:int(len(rewards)*train_set_size)], 
                choices[:int(len(rewards)*train_set_size)], 
                lasers[:int(len(rewards)*train_set_size)])
            simulate_data_test = (rewards[int(len(rewards)*train_set_size):], 
                                  contrasts[int(len(rewards)*train_set_size):], 
                                  choices[int(len(rewards)*train_set_size):], 
                          lasers[int(len(rewards)*train_set_size):], 
                          laser_side[int(len(rewards)*train_set_size):])
        else:
            data_test = data
            simulate_data_test = simulate_data
        

        (best_x_stay, train_NLL_stay, buffer_NLL_stay, 
         buffer_x_stay) = optimizer_stay(data, initial_guess=[0.3, 0.05, -1, 0.2,1, 1])
        
        cv_aic_stay = aic((session_neg_log_likelihood_stay(best_x_stay,
                  *data_test, pregen_all_posteriors=True))*-1,5)
        
       
        cv_LL_stay = (session_neg_log_likelihood_stay(best_x_stay, *data_test,
                                                      pregen_all_posteriors=True))*-1
       
        
        
        _, cv_acc_stay = session_neg_log_likelihood_stay(best_x_stay, *data_test, 
                       pregen_all_posteriors=True, accu=True)
       
        
        model_parameters_mouse = pd.DataFrame()
        model_parameters_mouse['x'] = [best_x_stay]
        model_parameters_mouse['LL'] = (cv_LL_stay/len(data_test[0]))
        model_parameters_mouse['aic'] = cv_aic_stay
        model_parameters_mouse['accu'] = cv_acc_stay
        model_parameters_mouse['model_name'] = 'w_stay'

        
        sim_data = generate_data_stay(simulate_data_test, all_contrasts, learning_rate=best_x_stay[0], 
                                       beliefSTD=best_x_stay[1], extraVal=best_x_stay[2], beta=best_x_stay[3], stay=best_x_stay[4],
                                       extraVal_nowater =best_x_stay[5])
        sim_data = pd.DataFrame(sim_data)
        
        sim_data = sim_data.rename(columns={0: "rewards", 1: "signed_contrast", 2: "simulated_choices", 3: "model_laser"})
        sim_data = np.array(sim_data)
        sim_data = pd.DataFrame(sim_data).T
        sim_data['laser'] = lasers[:int(len(rewards)*train_set_size)]
        sim_data['laser_side'] = laser_side[:int(len(rewards)*train_set_size)]
        sim_data['real_choice'] = choices[:int(len(rewards)*train_set_size)]
        sim_data['mouse_name']  = mouse
        sim_data['virus']  = virus
        sim_data['real_rewards']  = simulate_data[0]
       
        # Concatenate with general dataframes
        model_parameters_mouse['mouse'] = mouse
        model_parameters_mouse['virus'] = virus
        
        # Concatenate with general dataframes
        model_parameters = pd.concat([model_parameters, model_parameters_mouse])
        modelled_data = pd.concat([modelled_data, sim_data])
        
    return model_parameters

def model_2_laser_wo_stay():
        
    def true_stim_posterior(true_contrast, beliefSTD):
    	# Compute distribution over perceived contrast
    	# start_time = time.time()
    
    	def f(x):
    		return norm.cdf(x,0,beliefSTD) * norm.pdf(x,true_contrast,beliefSTD)
        
    	bs_right = quad(f,-np.inf, +np.inf)
    	return [1-bs_right[0],bs_right[0]]
    

    # Given all of the Q values (a matrix of size num_contrasts x 2), compute the overall Q_left and Q_right 
    # (i.e., the overall value of choosing left or right) given the perceived stimulus
    def compute_QL_QR(Q, trial_contrast, contrast_posterior):
    	Q_L = 0
    	Q_R = 0
    
    	# We compute Q_L, Q_R as in the Cell paper, by taking the weighted average of the various perceived stimuli,
    	# according to the probability that they were perceived
    	for i in range(len(contrast_posterior)):
    		Q_L += contrast_posterior[i] * Q[i, 0]
    		Q_R += contrast_posterior[i] * Q[i, 1]
    
    	return Q_L, Q_R
    
    def softmax_stay(Q_L, Q_R, beta):
    	p = [np.exp(Q_L / beta),
          np.exp(Q_R / beta)]
    	p /= np.sum(p)
    
    	return p
    
    def trial_log_likelihood_stay(params, trial_data, Q, all_contrasts, all_posteriors, 
                                  previous_trial, trial_num, retrieve_Q = False):
    	# Get relevant parameters
    	trial_contrast, trial_choice, reward, laser = trial_data
    	learning_rate, beliefSTD, extraVal, beta, extraVal_nowater_guess = params
    	extraVal_nowater_guess = extraVal
        
    
    	# Compute the log-likelihood of the actual mouse choice
    	if all_posteriors is None:
    		contrast_posterior = true_stim_posterior(trial_contrast, beliefSTD)
    	else:
    		posterior_idx = np.argmin(np.abs(all_contrasts - trial_contrast))
    		contrast_posterior = all_posteriors[posterior_idx, :]
    
    	Q_L, Q_R = compute_QL_QR(Q, trial_contrast, contrast_posterior)
    	
        
    	choice_dist = softmax_stay(Q_L, Q_R, beta)
    	LL = np.log(choice_dist[trial_choice])	
    
    	# Learning
    	if trial_choice == 0:
    		Q_chosen = Q_L
    	else:
    		Q_chosen = Q_R
    
    	# Laser-modulation
    	if laser == 1:
    		if reward ==1:
    			received_reward = reward + extraVal
    		else:
    			received_reward = extraVal_nowater_guess
    	else:
    		received_reward = reward
    
    	# Update Q-values according to the aggregate reward + laser value
    	for i in range(2):
    		Q[i, trial_choice] += contrast_posterior[i] * learning_rate * (received_reward - Q_chosen)
    
    	if retrieve_Q==True:
    		return LL, Q, Q_L, Q_R, choice_dist[1] #  choice_dist[1] = pChoice_right
    	else:
    		return LL, Q
    
    
    
    def session_neg_log_likelihood_stay(params, *data, pregen_all_posteriors=True, accu=False, retrieve_Q =  False):
    	# Unpack the arguments
    	learning_rate, beliefSTD, extraVal, beta, extraVal_nowater_guess = params
    	rewards, true_contrasts, choices, lasers = data
    	num_trials = len(rewards)
        
    	if retrieve_Q==True:
    		Q_L = []
    		Q_R = []
    		pRight = []
    
    	# Generate the possible contrast list
    	all_contrasts = np.array([-0.25, -0.125, -0.6125, 0, 0.6125, 0.125, 0.25])
    	num_contrasts = len(all_contrasts)
    
    	# If True, generate all posterior distributions ahead of time to save time
    	if pregen_all_posteriors:
    		all_posteriors = np.zeros((num_contrasts, 2))
    		for idx, contrast in enumerate(all_contrasts):
    			all_posteriors[idx, :] = true_stim_posterior(contrast, beliefSTD)
    	else:
    		all_posteriors = None
    
    	# Compute the log-likelihood
    	if accu == True:
    		acc = 0
    	LL = 0
    	Q = np.zeros([2, 2])
        
    	if retrieve_Q == True:
                
    		for i in range(num_trials):
    			if i == 0:
    			    trial_LL, newQ, Q_Lt, Q_Rt, pright = trial_log_likelihood_stay(params, 
                                                [true_contrasts[i], choices[i], rewards[i], lasers[i]], 
                                                Q, all_contrasts, all_posteriors, np.nan, i, retrieve_Q=retrieve_Q)
    			else:
    			    trial_LL, newQ, Q_Lt, Q_Rt, pright = trial_log_likelihood_stay(params, 
                                                [true_contrasts[i], choices[i], rewards[i], lasers[i]], 
                                                Q, all_contrasts, all_posteriors, choices[i-1], i, retrieve_Q=retrieve_Q)
    			LL += trial_LL
    			Q = newQ
                
    			if accu == True:
    				acc += (np.exp(trial_LL)>0.5)*1
                
    			Q_L.append(Q_Lt)
    			Q_R.append(Q_Rt)
    			pRight.append(pright)
            
    		
    	else:        
    		for i in range(num_trials):
    			if i == 0:
    			    trial_LL, newQ = trial_log_likelihood_stay(params, 
                                                [true_contrasts[i], choices[i], rewards[i], lasers[i]], 
                                                Q, all_contrasts, all_posteriors, np.nan, i)
    			else:
    			    trial_LL, newQ = trial_log_likelihood_stay(params, 
                                                [true_contrasts[i], choices[i], rewards[i], lasers[i]], 
                                                Q, all_contrasts, all_posteriors, choices[i-1], i)
    			LL += trial_LL
    			Q = newQ
                
    			if accu == True:
    				acc += (np.exp(trial_LL)>0.5)*1
                    
    
    	if retrieve_Q == True:   
    		if accu == True:
    			acc = acc/num_trials
    			return -LL,  acc, Q_L, Q_R, pRight
    		else:
    			return -LL, Q_L, Q_R, pRight
    
    	else:
    		if accu == True:
    			acc = acc/num_trials
    			return -LL,  acc
    		else:
    			return -LL
    
    
    
    
    
    # Optimize several times with different initializations and return the best fit parameters, and negative log likelihood
    
    def optimizer_stay(data, num_fits = 4, initial_guess=[0.1, 1, 0, 1,0]):
    	# Accounting variables
    	best_NLL = np.Inf
    	best_x = [None, None, None, None, None]
    	buffer_NLL = []
    	buffer_x = np.empty([num_fits,len(initial_guess)])
    	# Do our fit with several different initializations
    	for i in range(num_fits):
    		print('Starting fit %d' % i)
    
    		# For every fit other than the first, construct a new initial guess
    		if i != 0:
    			lr_guess = np.random.uniform(0, 2)
    			beliefSTD_guess = np.random.uniform(0.03, 1)
    			extraVal_guess = np.random.uniform(-2,2)
    			beta_guess = np.random.uniform(0.01, 1)
    			extraVal_nowater_guess = np.random.uniform(-2,2)
    			initial_guess = [lr_guess, beliefSTD_guess, extraVal_guess, beta_guess, extraVal_nowater_guess]
    
    		# Run the fit
    		res = so.minimize(session_neg_log_likelihood_stay, initial_guess, args=data, 
                        method='L-BFGS-B', bounds=[(0, 2), (0.03, 1), (-2, 2), (0.01, 1), 
                                        (-2, 2)])
    
    		# If this fit is better than the previous best, remember it, otherwise toss
    		buffer_x[i,:] = res.x
    		buffer_NLL.append(res.fun)
            
    		if res.fun <= best_NLL:
    			best_NLL = res.fun
    			best_x = res.x
    
    	return best_x, best_NLL, buffer_NLL, buffer_x
    
    
    
    # hardcode this for speed
    def normal_pdf(x, loc, scale):
    	factor = 1 / (np.sqrt(2 * np.pi) * scale)
    	power = -0.5 * (((x - loc) / scale) ** 2)
    
    	return factor * np.exp(power)
    
    ##### Analysis functions
    
    def accuracy_per_contrast(data, all_contrasts):
    	rewards, contrasts, choices, lasers = data
    	num_trials = len(rewards)
    
    	acc = np.zeros(len(all_contrasts))
    	trials_per_contrast = np.zeros(len(all_contrasts))
    	for i in range(num_trials):
    		reward = rewards[i]
    		contrast = contrasts[i]
    		choice = choices[i]
    		laser = lasers[i]
    
    		contrast_idx = np.argmin(np.abs(all_contrasts - contrast))
    		
    		if reward > 0:
    			acc[contrast_idx] += 1
    
    		trials_per_contrast[contrast_idx] += 1
    
    	acc /= trials_per_contrast
    
    	return acc
    
    def psychometric_curve(data, all_contrasts):
    	rewards, contrasts, choices, lasers = data
    	num_trials = len(rewards)
    
    	p_right = np.zeros(len(all_contrasts))
    	trials_per_contrast = np.zeros(len(all_contrasts))
    	for i in range(num_trials):
    		reward = rewards[i]
    		contrast = contrasts[i]
    		choice = choices[i]
    		laser = lasers[i]
    
    		contrast_idx = np.argmin(np.abs(all_contrasts - contrast))
    		
    		if choice == 1:
    			p_right[contrast_idx] += 1
    
    		trials_per_contrast[contrast_idx] += 1
    
    	p_right /= trials_per_contrast
    
    	return p_right
    
    ##### TESTING SCRIPT #####
    
    def simulation_contrast_distribution(mean_contrast, beliefSTD, all_contrasts):
    	# Compute distribution of final perceived contrasts
    	p = normal_pdf(all_contrasts, loc=mean_contrast, scale=beliefSTD)
    
    	# Renormalize
    	p /= np.sum(p)
    
    	return p
    
    
    def generate_data_stay(data, all_contrasts, learning_rate=0.3, 
                           beliefSTD=0.1, extraVal=1, beta=0.2, 
                           extraVal_nowater = 1, is_verbose=False, 
                           propagate_errors = True):
        
    	rewards = []
    	true_contrasts = []
    	choices = []
    	lasers = []
        
    	if propagate_errors == False:
    		prop = 3
    	else:
    		prop = 4
    
    	# Simulate the POMDP model
    	Q = np.zeros([2, 2])
    	for t in range(len(data[0])):
    		if is_verbose:
    			print(t)
    
    		# Pick a true stimulus and store
    		trial_contrast = data[1][t]
    		true_contrasts.append(trial_contrast)
            # Add noise
    		perceived_contrast_distribution = simulation_contrast_distribution(trial_contrast, beliefSTD, all_contrasts)
    		perceived_contrast = np.random.choice(all_contrasts, p=perceived_contrast_distribution)
            
    		contrast_posterior = [0,0]
    		contrast_posterior[0] = norm.cdf(0, loc = perceived_contrast, scale = beliefSTD)
    		contrast_posterior[1] = 1 - contrast_posterior[0]
            
    		Q_L, Q_R = compute_QL_QR(Q, perceived_contrast, contrast_posterior)
    
    		
    		choice_dist = softmax_stay(Q_L, Q_R, beta)
    		choice = np.random.choice(2, p = [float(choice_dist[0]), float(choice_dist[1])])
    		choices.append(choice)
    
    		# Get reward and store it
    		if np.sign(trial_contrast) == -1 and choice == 0:
    			reward = 1
    		elif np.sign(trial_contrast) == 1 and choice == 1:
    			reward = 1
    		elif np.sign(trial_contrast) == 0:
    			reward = random.choice([0,1])      
    		else:
    			reward = 0
    
    		rewards.append(reward)
    		
    		# Add laser value on the correct condition
    		if propagate_errors == True:
    			if choice == data[prop][t]:
    			    reward += extraVal
    			    lasers.append(1)
    			else:
    			    lasers.append(-1)
    		else:
    			reward = data[0][t]
    			if reward == 0:
    			    reward = extraVal_nowater
    			else:
    			    reward += extraVal*data[prop][t]
    			    lasers.append(data[prop][t])
    		# Learn (update Q-values)
    		if choice == 0:
    			Q_chosen = Q_L
    		else:
    			Q_chosen = Q_R
            
    		contrast_posterior = [0,0]
    		contrast_posterior[0] = norm.cdf(0, loc = perceived_contrast, scale = beliefSTD)
    		contrast_posterior[1] = 1 - contrast_posterior[0]
    
    		for i in range(2):
    			Q[i, choice] += contrast_posterior[i] * learning_rate * (reward - Q_chosen)
    
    	return rewards, true_contrasts, choices, lasers
    
    def transform_model_struct_2_POMDP(model_data, simulate_data):
            simulate_data.loc[simulate_data['extraRewardTrials'] == 'right', 'extraRewardTrials' ] = 1
            simulate_data.loc[simulate_data['extraRewardTrials'] == 'left', 'extraRewardTrials' ] = 0
            simulate_data.loc[simulate_data['extraRewardTrials'] == 'none', 'extraRewardTrials' ] = -1
            obj = model_data
            obj['choice'] = obj['choice'] * -1
            obj.loc[obj['choice'] == -1, 'choice'] = 0
            obj['laser_side'] = simulate_data['extraRewardTrials']
            return obj
    
    def likelihood_ratio(llmin, llmax):
        return(2*(llmax-llmin))
    
    def aic(LL,n_param):
        # Calculates Akaike Information Criterion
        aic =  2*n_param - 2*LL
        return aic
        
    def chi2_LLR(L1,L2):
        LR = likelihood_ratio(L1,L2)
        p = chi2.sf(LR, 1) # L2 has 1 DoF more than L1
        return p
        

	# print(x)
    mice = np.array(['dop_8', 'dop_9', 'dop_11', 'dop_4', 'dop_7'])

	# Load Alex's actual data
    psy = pd.read_pickle('all_behav.pkl')

    train_set_size = 1
    cross_validate = False
     
    all_contrasts = np.array([-0.25  , -0.125 , -0.0625,  0.    ,  0.0625, 0.125 , 0.25  ])
    best_nphr_individual = np.zeros([len(psy.loc[psy['virus'] == 'nphr', 'mouse_name'].unique()),4])
    best_nphr_NLL_individual = np.zeros([len(psy.loc[psy['virus'] == 'nphr', 'mouse_name'].unique()),1])
    model_parameters = pd.DataFrame()
    modelled_data = pd.DataFrame()
    for i, mouse in enumerate(mice): 
        model_data_nphr, simulate_data_nphr  = \
            psy_df_to_Q_learning_model_format(psy.loc[psy['mouse_name'] == mouse], 
                                              virus = psy.loc[psy['mouse_name'] == mouse, 'virus'].unique()[0])
        
        
        obj = transform_model_struct_2_POMDP(model_data_nphr, simulate_data_nphr)
        
        virus = psy.loc[psy['mouse_name'] == mouse, 'virus'].unique()[0]
        
        opto = obj['extraRewardTrials'].to_numpy()
        lasers = []
        for i in range(len(opto)):
            try:
                lasers.append(int(opto[i][0]))
            except:
                lasers.append(int(opto[i]))
    
        choices = list(obj['choice'].to_numpy())
        contrasts = list(obj['stimTrials'].to_numpy())
        rewards = list(obj['reward'].to_numpy())
        laser_side = list(obj['laser_side'].to_numpy())
    
        
        data = (rewards[:int(len(rewards)*train_set_size)],
                contrasts[:int(len(rewards)*train_set_size)], 
                choices[:int(len(rewards)*train_set_size)], 
                lasers[:int(len(rewards)*train_set_size)])
        simulate_data = (rewards[:int(len(rewards)*train_set_size)], 
                         contrasts[:int(len(rewards)*train_set_size)], 
                         choices[:int(len(rewards)*train_set_size)], 
                      lasers[:int(len(rewards)*train_set_size)], 
                      laser_side[:int(len(rewards)*train_set_size)])
        
        if cross_validate == True:
            
            data = (rewards[:int(len(rewards)*train_set_size)],
                contrasts[:int(len(rewards)*train_set_size)], 
                choices[:int(len(rewards)*train_set_size)], 
                lasers[:int(len(rewards)*train_set_size)])
            simulate_data_test = (rewards[int(len(rewards)*train_set_size):], 
                                  contrasts[int(len(rewards)*train_set_size):], 
                                  choices[int(len(rewards)*train_set_size):], 
                          lasers[int(len(rewards)*train_set_size):], 
                          laser_side[int(len(rewards)*train_set_size):])
        else:
            data_test = data
            simulate_data_test = simulate_data
        

        (best_x_stay, train_NLL_stay, buffer_NLL_stay, 
         buffer_x_stay) = optimizer_stay(data, initial_guess=[0.3, 0.05, -1, 0.2, 1])
        
        cv_aic_stay = aic((session_neg_log_likelihood_stay(best_x_stay,
                  *data_test, pregen_all_posteriors=True))*-1,5)
        
       
        cv_LL_stay = (session_neg_log_likelihood_stay(best_x_stay, *data_test,
                                                      pregen_all_posteriors=True))*-1
       
        
        
        _, cv_acc_stay = session_neg_log_likelihood_stay(best_x_stay, *data_test, 
                       pregen_all_posteriors=True, accu=True)
       
        
        model_parameters_mouse = pd.DataFrame()
        model_parameters_mouse['x'] = [best_x_stay]
        model_parameters_mouse['LL'] = (cv_LL_stay/len(data_test[0]))
        model_parameters_mouse['aic'] = cv_aic_stay
        model_parameters_mouse['accu'] = cv_acc_stay
        model_parameters_mouse['model_name'] = 'w_stay'

        
        sim_data = generate_data_stay(simulate_data_test, all_contrasts, learning_rate=best_x_stay[0], 
                                       beliefSTD=best_x_stay[1], extraVal=best_x_stay[2], beta=best_x_stay[3],
                                       extraVal_nowater =best_x_stay[4])
        sim_data = pd.DataFrame(sim_data)
        
        sim_data = sim_data.rename(columns={0: "rewards", 1: "signed_contrast", 2: "simulated_choices", 3: "model_laser"})
        sim_data = np.array(sim_data)
        sim_data = pd.DataFrame(sim_data).T
        sim_data['laser'] = lasers[:int(len(rewards)*train_set_size)]
        sim_data['laser_side'] = laser_side[:int(len(rewards)*train_set_size)]
        sim_data['real_choice'] = choices[:int(len(rewards)*train_set_size)]
        sim_data['mouse_name']  = mouse
        sim_data['virus']  = virus
        sim_data['real_rewards']  = simulate_data[0]
       
        # Concatenate with general dataframes
        model_parameters_mouse['mouse'] = mouse
        model_parameters_mouse['virus'] = virus
        
        # Concatenate with general dataframes
        model_parameters = pd.concat([model_parameters, model_parameters_mouse])
        modelled_data = pd.concat([modelled_data, sim_data])
        
    return model_parameters

def model_wo_laser_w_stay():
        
    def true_stim_posterior(true_contrast, beliefSTD):
    	# Compute distribution over perceived contrast
    	# start_time = time.time()
    
    	def f(x):
    		return norm.cdf(x,0,beliefSTD) * norm.pdf(x,true_contrast,beliefSTD)
        
    	bs_right = quad(f,-np.inf, +np.inf)
    	return [1-bs_right[0],bs_right[0]]
    
    
    # Given all of the Q values (a matrix of size num_contrasts x 2), compute the overall Q_left and Q_right 
    # (i.e., the overall value of choosing left or right) given the perceived stimulus
    def compute_QL_QR(Q, trial_contrast, contrast_posterior):
    	Q_L = 0
    	Q_R = 0
    
    	# We compute Q_L, Q_R as in the Cell paper, by taking the weighted average of the various perceived stimuli,
    	# according to the probability that they were perceived
    	for i in range(len(contrast_posterior)):
    		Q_L += contrast_posterior[i] * Q[i, 0]
    		Q_R += contrast_posterior[i] * Q[i, 1]
    
    	return Q_L, Q_R
    
    def softmax_stay(Q_L, Q_R, beta, l_stay, r_stay, stay):
    	p = [np.exp(Q_L / beta + stay*l_stay),
          np.exp(Q_R / beta + stay*r_stay)]
    	p /= np.sum(p)
    
    	return p
    
    def trial_log_likelihood_stay(params, trial_data, Q, all_contrasts, all_posteriors, 
                                  previous_trial, trial_num, retrieve_Q = False, retrieve_ITIQ = False):
    	# Get relevant parameters
    	trial_contrast, trial_choice, reward, laser = trial_data
    	learning_rate, beliefSTD, beta, stay = params
    	Q =  Q.copy()
    
    	# Compute the log-likelihood of the actual mouse choice
    	if all_posteriors is None:
    		contrast_posterior = true_stim_posterior(trial_contrast, beliefSTD)
    	else:
    		posterior_idx = np.argmin(np.abs(all_contrasts - trial_contrast))
    		contrast_posterior = all_posteriors[posterior_idx, :]
    
    	Q_L, Q_R = compute_QL_QR(Q, trial_contrast, contrast_posterior)
    	if trial_num == 0:
    		(l_stay, r_stay) = [0,0]
    	else:
    		previous_choice= [0,0]
    		previous_choice[previous_trial] = 1
    		(l_stay, r_stay) = previous_choice
        
    	choice_dist = softmax_stay(Q_L, Q_R, beta,l_stay, r_stay, stay)
    	LL = np.log(choice_dist[trial_choice])	
    
    	# Learning
    	if trial_choice == 0:
    		Q_chosen = Q_L
    	else:
    		Q_chosen = Q_R
    
    	# Laser-modulation
    	if laser == 1:
    		received_reward = reward
    	else:
    		received_reward = reward
    
    	# Update Q-values according to the aggregate reward + laser value
    	for i in range(2):
    		Q[i, trial_choice] += contrast_posterior[i] * learning_rate * (received_reward - Q_chosen)
    
    	if retrieve_ITIQ == True:
    		Q_L = np.sum(Q, axis=0)[0]
    		Q_R = np.sum(Q, axis=0)[1]
    
    
    	if retrieve_Q==True:
    		return LL, Q, Q_L, Q_R, choice_dist[1] #  choice_dist[1] = pChoice_right
        
    	else:
    		return LL, Q
    
    
    
    def session_neg_log_likelihood_stay(params, *data, pregen_all_posteriors=True, 
                                        accu=False, retrieve_Q =  False, retrieve_ITIQ = False):
    	# Unpack the arguments
    	learning_rate, beliefSTD, beta, stay = params
    	rewards, true_contrasts, choices, lasers = data
    	num_trials = len(rewards)
        
    	if retrieve_Q==True:
    		Q_L = []
    		Q_R = []
    		pRight = []
    
    	# Generate the possible contrast list
    	all_contrasts = np.array([-0.25, -0.125, -0.0625, 0, 0.0625, 0.125, 0.25])
    	num_contrasts = len(all_contrasts)
    
    	# If True, generate all posterior distributions ahead of time to save time
    	if pregen_all_posteriors:
    		all_posteriors = np.zeros((num_contrasts, 2))
    		for idx, contrast in enumerate(all_contrasts):
    			all_posteriors[idx, :] = true_stim_posterior(contrast, beliefSTD)
    	else:
    		all_posteriors = None
    
    	# Compute the log-likelihood
    	if accu == True:
    		acc = 0
    	LL = 0
    	Q = np.zeros([2, 2])
        
    	if retrieve_Q == True:
                
    		for i in range(num_trials):
    			if i == 0:
    			    trial_LL, newQ, Q_Lt, Q_Rt, pright = trial_log_likelihood_stay(params, 
                                                [true_contrasts[i], choices[i], rewards[i], lasers[i]], 
                                                Q, all_contrasts, all_posteriors, 
                                                np.nan, i, retrieve_Q=retrieve_Q, retrieve_ITIQ=retrieve_ITIQ)
    			else:
    			    trial_LL, newQ, Q_Lt, Q_Rt, pright = trial_log_likelihood_stay(params, 
                                                [true_contrasts[i], choices[i], rewards[i], lasers[i]], 
                                                Q, all_contrasts, all_posteriors, 
                                                choices[i-1], i, retrieve_Q=retrieve_Q, retrieve_ITIQ=retrieve_ITIQ)
    
    			if (i != 0) & (np.sum(Q, axis=0)[0] != np.sum(newQ, axis=0)[0]) & (np.sum(Q, axis=0)[1] != np.sum(newQ, axis=0)[1]):
    				print('Warning, double update error in trial %d'%i)
    			LL += trial_LL
    			Q = newQ
                
    			if accu == True:
    				acc += (np.exp(trial_LL)>0.5)*1
                
    			Q_L.append(Q_Lt)
    			Q_R.append(Q_Rt)
    			pRight.append(pright)
            
    		
    	else:        
    		for i in range(num_trials):
    			if i == 0:
    			    trial_LL, newQ = trial_log_likelihood_stay(params, 
                                                [true_contrasts[i], choices[i], rewards[i], lasers[i]], 
                                                Q, all_contrasts, all_posteriors, np.nan, i)
    			else:
    			    trial_LL, newQ = trial_log_likelihood_stay(params, 
                                                [true_contrasts[i], choices[i], rewards[i], lasers[i]], 
                                                Q, all_contrasts, all_posteriors, choices[i-1], i)
    			LL += trial_LL
    			Q = newQ
                
    			if accu == True:
    				acc += (np.exp(trial_LL)>0.5)*1
                    
    
    	if retrieve_Q == True:   
    		if accu == True:
    			acc = acc/num_trials
    			return -LL,  acc, Q_L, Q_R, pRight
    		else:
    			return -LL, Q_L, Q_R, pRight
    
    	else:
    		if accu == True:
    			acc = acc/num_trials
    			return -LL,  acc
    		else:
    			return -LL
    
    
    
    
    
    # Optimize several times with different initializations and return the best fit parameters, and negative log likelihood
    
    def optimizer_stay(data, num_fits = 4, initial_guess=[0.1, 1, 1, 1]):
    	# Accounting variables
    	best_NLL = np.Inf
    	best_x = [None, None, None, None]
    	buffer_NLL = []
    	buffer_x = np.empty([num_fits,len(initial_guess)])
    	# Do our fit with several different initializations
    	for i in range(num_fits):
    		print('Starting fit %d' % i)
    
    		# For every fit other than the first, construct a new initial guess
    		if i != 0:
    			lr_guess = np.random.uniform(0, 2)
    			beliefSTD_guess = np.random.uniform(0.03, 1)
    			beta_guess = np.random.uniform(0.01, 1)
    			stay = np.random.uniform(-1, 1)
    			initial_guess = [lr_guess, beliefSTD_guess, beta_guess, stay]
    
    		# Run the fit
    		res = so.minimize(session_neg_log_likelihood_stay, initial_guess, args=data, 
                        method='L-BFGS-B', bounds=[(0, 2), (0.03, 1), (0.01, 1), 
                                        (-1,1)])
    
    		# If this fit is better than the previous best, remember it, otherwise toss
    		buffer_x[i,:] = res.x
    		buffer_NLL.append(res.fun)
            
    		if res.fun <= best_NLL:
    			best_NLL = res.fun
    			best_x = res.x
    
    	return best_x, best_NLL, buffer_NLL, buffer_x
    
    
    
    # hardcode this for speed
    def normal_pdf(x, loc, scale):
    	factor = 1 / (np.sqrt(2 * np.pi) * scale)
    	power = -0.5 * (((x - loc) / scale) ** 2)
    
    	return factor * np.exp(power)
    
    ##### Analysis functions
    
    def accuracy_per_contrast(data, all_contrasts):
    	rewards, contrasts, choices, lasers = data
    	num_trials = len(rewards)
    
    	acc = np.zeros(len(all_contrasts))
    	trials_per_contrast = np.zeros(len(all_contrasts))
    	for i in range(num_trials):
    		reward = rewards[i]
    		contrast = contrasts[i]
    		choice = choices[i]
    		laser = lasers[i]
    
    		contrast_idx = np.argmin(np.abs(all_contrasts - contrast))
    		
    		if reward > 0:
    			acc[contrast_idx] += 1
    
    		trials_per_contrast[contrast_idx] += 1
    
    	acc /= trials_per_contrast
    
    	return acc
    
    def psychometric_curve(data, all_contrasts):
    	rewards, contrasts, choices, lasers = data
    	num_trials = len(rewards)
    
    	p_right = np.zeros(len(all_contrasts))
    	trials_per_contrast = np.zeros(len(all_contrasts))
    	for i in range(num_trials):
    		reward = rewards[i]
    		contrast = contrasts[i]
    		choice = choices[i]
    		laser = lasers[i]
    
    		contrast_idx = np.argmin(np.abs(all_contrasts - contrast))
    		
    		if choice == 1:
    			p_right[contrast_idx] += 1
    
    		trials_per_contrast[contrast_idx] += 1
    
    	p_right /= trials_per_contrast
    
    	return p_right
    
    ##### TESTING SCRIPT #####
    
    def simulation_contrast_distribution(mean_contrast, beliefSTD, all_contrasts):
    	# Compute distribution of final perceived contrasts
    	p = normal_pdf(all_contrasts, loc=mean_contrast, scale=beliefSTD)
    
    	# Renormalize
    	p /= np.sum(p)
    
    	return p
    
    
    def generate_data_stay(data, all_contrasts, learning_rate=0.3, 
                           beliefSTD=0.1, beta=0.2, 
                           stay = 1, is_verbose=False, propagate_errors = True):
    	
    	rewards = []
    	true_contrasts = []
    	choices = []
    	lasers = []
        
    	if propagate_errors == False:
    		prop = 3
    	else:
    		prop = 4
    
    	# Simulate the POMDP model
    	Q = np.zeros([2, 2])
    	for t in range(len(data[0])):
    		if is_verbose:
    			print(t)
    
    		# Pick a true stimulus and store
    		trial_contrast = data[1][t]
    		true_contrasts.append(trial_contrast)
            # Add noise
    		perceived_contrast_distribution = simulation_contrast_distribution(trial_contrast, beliefSTD, all_contrasts)
    		perceived_contrast = np.random.choice(all_contrasts, p=perceived_contrast_distribution)
            
    		contrast_posterior = [0,0]
    		contrast_posterior[0] = norm.cdf(0, loc = trial_contrast, scale = beliefSTD)
    		contrast_posterior[1] = 1 - contrast_posterior[0]
            
    		Q_L, Q_R = compute_QL_QR(Q, perceived_contrast, contrast_posterior)
    
    		if t == 0:
    		    (l_stay, r_stay) = [0,0]
    		else:
    		    previous_choice= [0,0]
    		    previous_choice[choices[t-1]] = 1
    		    (l_stay, r_stay) = previous_choice
    		choice_dist = softmax_stay(Q_L, Q_R, beta,l_stay, r_stay, stay)
    		choice = np.random.choice(2, p = [float(choice_dist[0]), float(choice_dist[1])])
    		choices.append(choice)
    
    		# Get reward and store it
    		if np.sign(trial_contrast) == -1 and choice == 0:
    			reward = 1
    		elif np.sign(trial_contrast) == 1 and choice == 1:
    			reward = 1
    		elif np.sign(trial_contrast) == 0:
    			reward = random.choice([0,1])      
    		else:
    			reward = 0
    
    		rewards.append(reward)
    		
    		# Add laser value on the correct condition
    		if propagate_errors == True:
    			if choice == data[prop][t]:
    			    reward += 0
    			    lasers.append(1)
    			else:
    			    lasers.append(-1)
    		else:
    			reward = data[0][t]
    			reward += 0
    			lasers.append(data[prop][t])
    		# Learn (update Q-values)
    		if choice == 0:
    			Q_chosen = Q_L
    		else:
    			Q_chosen = Q_R
            
    		contrast_posterior = [0,0]
    		contrast_posterior[0] = norm.cdf(0, loc = trial_contrast, scale = beliefSTD)
    		contrast_posterior[1] = 1 - contrast_posterior[0]
    
    		for i in range(2):
    			Q[i, choice] += contrast_posterior[i] * learning_rate * (reward - Q_chosen)
    
    	return rewards, true_contrasts, choices, lasers
    
    def transform_model_struct_2_POMDP(model_data, simulate_data):
            simulate_data.loc[simulate_data['extraRewardTrials'] == 'right', 'extraRewardTrials' ] = 1
            simulate_data.loc[simulate_data['extraRewardTrials'] == 'left', 'extraRewardTrials' ] = 0
            simulate_data.loc[simulate_data['extraRewardTrials'] == 'none', 'extraRewardTrials' ] = -1
            obj = model_data
            obj['choice'] = obj['choice'] * -1
            obj.loc[obj['choice'] == -1, 'choice'] = 0
            obj['laser_side'] = simulate_data['extraRewardTrials']
            return obj
    
    def likelihood_ratio(llmin, llmax):
        return(2*(llmax-llmin))
    
    def aic(LL,n_param):
        # Calculates Akaike Information Criterion
        aic =  2*n_param - 2*LL
        return aic
        
    def chi2_LLR(L1,L2):
        LR = likelihood_ratio(L1,L2)
        p = chi2.sf(LR, 1) # L2 has 1 DoF more than L1
        return p

    mice = np.array(['dop_8', 'dop_9', 'dop_11', 'dop_4', 'dop_7'])
    
    # Load Alex's actual data
    psy = pd.read_pickle('all_behav.pkl')
    
    train_set_size = 1
    cross_validate = False
         
    all_contrasts = np.array([-0.25  , -0.125 , -0.0625,  0.    ,  0.0625, 0.125 , 0.25  ])
    best_nphr_individual = np.zeros([len(psy.loc[psy['virus'] == 'nphr', 'mouse_name'].unique()),4])
    best_nphr_NLL_individual = np.zeros([len(psy.loc[psy['virus'] == 'nphr', 'mouse_name'].unique()),1])
    model_parameters = pd.DataFrame()
    modelled_data = pd.DataFrame()
    for i, mouse in enumerate(mice): 
            model_data_nphr, simulate_data_nphr  = \
                psy_df_to_Q_learning_model_format(psy.loc[psy['mouse_name'] == mouse], 
                                                  virus = psy.loc[psy['mouse_name'] == mouse, 'virus'].unique()[0])
            
            
            obj = transform_model_struct_2_POMDP(model_data_nphr, simulate_data_nphr)
            
            virus = psy.loc[psy['mouse_name'] == mouse, 'virus'].unique()[0]
            
            opto = obj['extraRewardTrials'].to_numpy()
            lasers = []
            for i in range(len(opto)):
                try:
                    lasers.append(int(opto[i][0]))
                except:
                    lasers.append(int(opto[i]))
        
            choices = list(obj['choice'].to_numpy())
            contrasts = list(obj['stimTrials'].to_numpy())
            rewards = list(obj['reward'].to_numpy())
            laser_side = list(obj['laser_side'].to_numpy())
        
            
            data = (rewards[:int(len(rewards)*train_set_size)],
                    contrasts[:int(len(rewards)*train_set_size)], 
                    choices[:int(len(rewards)*train_set_size)], 
                    lasers[:int(len(rewards)*train_set_size)])
            simulate_data = (rewards[:int(len(rewards)*train_set_size)], 
                             contrasts[:int(len(rewards)*train_set_size)], 
                             choices[:int(len(rewards)*train_set_size)], 
                          lasers[:int(len(rewards)*train_set_size)], 
                          laser_side[:int(len(rewards)*train_set_size)])
            
            if cross_validate == True:
                
                data = (rewards[:int(len(rewards)*train_set_size)],
                    contrasts[:int(len(rewards)*train_set_size)], 
                    choices[:int(len(rewards)*train_set_size)], 
                    lasers[:int(len(rewards)*train_set_size)])
                simulate_data_test = (rewards[int(len(rewards)*train_set_size):], 
                                      contrasts[int(len(rewards)*train_set_size):], 
                                      choices[int(len(rewards)*train_set_size):], 
                              lasers[int(len(rewards)*train_set_size):], 
                              laser_side[int(len(rewards)*train_set_size):])
            else:
                data_test = data
                simulate_data_test = simulate_data
            
    
            (best_x_stay, train_NLL_stay, buffer_NLL_stay, 
             buffer_x_stay) = optimizer_stay(data, initial_guess=[0.3, 0.05, 0.2,1])
            
            cv_aic_stay = aic((session_neg_log_likelihood_stay(best_x_stay,
                      *data_test, pregen_all_posteriors=True))*-1,5)
            
           
            cv_LL_stay = (session_neg_log_likelihood_stay(best_x_stay, *data_test,
                                                          pregen_all_posteriors=True))*-1
           
            
            
            _, cv_acc_stay = session_neg_log_likelihood_stay(best_x_stay, *data_test, 
                           pregen_all_posteriors=True, accu=True)
           
            
            model_parameters_mouse = pd.DataFrame()
            model_parameters_mouse['x'] = [best_x_stay]
            model_parameters_mouse['LL'] = (cv_LL_stay/len(data_test[0]))
            model_parameters_mouse['aic'] = cv_aic_stay
            model_parameters_mouse['accu'] = cv_acc_stay
            model_parameters_mouse['model_name'] = 'w_stay'
    
            
            sim_data = generate_data_stay(simulate_data_test, all_contrasts, learning_rate=best_x_stay[0],
                                       beliefSTD=best_x_stay[1], beta=best_x_stay[2],
                                       stay =best_x_stay[3])
            sim_data = pd.DataFrame(sim_data)
            
            sim_data = sim_data.rename(columns={0: "rewards", 1: "signed_contrast", 2: "simulated_choices", 3: "model_laser"})
            sim_data = np.array(sim_data)
            sim_data = pd.DataFrame(sim_data).T
            sim_data['laser'] = lasers[:int(len(rewards)*train_set_size)]
            sim_data['laser_side'] = laser_side[:int(len(rewards)*train_set_size)]
            sim_data['real_choice'] = choices[:int(len(rewards)*train_set_size)]
            sim_data['mouse_name']  = mouse
            sim_data['virus']  = virus
            sim_data['real_rewards']  = simulate_data[0]
           
            # Concatenate with general dataframes
            model_parameters_mouse['mouse'] = mouse
            model_parameters_mouse['virus'] = virus
            
            # Concatenate with general dataframes
            model_parameters = pd.concat([model_parameters, model_parameters_mouse])
            modelled_data = pd.concat([modelled_data, sim_data])
    
    return model_parameters

def model_wo_laser_wo_stay():

    def true_stim_posterior(true_contrast, beliefSTD):
    	# Compute distribution over perceived contrast
    	# start_time = time.time()
    
    	def f(x):
    		return norm.cdf(x,0,beliefSTD) * norm.pdf(x,true_contrast,beliefSTD)
        
    	bs_right = quad(f,-np.inf, +np.inf)
    	return [1-bs_right[0],bs_right[0]]
    
    
    # Given all of the Q values (a matrix of size num_contrasts x 2), compute the overall Q_left and Q_right 
    # (i.e., the overall value of choosing left or right) given the perceived stimulus
    def compute_QL_QR(Q, trial_contrast, contrast_posterior):
    	Q_L = 0
    	Q_R = 0
    
    	# We compute Q_L, Q_R as in the Cell paper, by taking the weighted average of the various perceived stimuli,
    	# according to the probability that they were perceived
    	for i in range(len(contrast_posterior)):
    		Q_L += contrast_posterior[i] * Q[i, 0]
    		Q_R += contrast_posterior[i] * Q[i, 1]
    
    	return Q_L, Q_R
    
    def softmax_stay(Q_L, Q_R, beta):
    	p = [np.exp(Q_L / beta),
          np.exp(Q_R / beta)]
    	p /= np.sum(p)
    
    	return p
    
    def trial_log_likelihood_stay(params, trial_data, Q, all_contrasts, all_posteriors, 
                                  previous_trial, trial_num, retrieve_Q = False, retrieve_ITIQ = False):
    	# Get relevant parameters
    	trial_contrast, trial_choice, reward, laser = trial_data
    	learning_rate, beliefSTD, beta = params
    	Q =  Q.copy()
    
    	# Compute the log-likelihood of the actual mouse choice
    	if all_posteriors is None:
    		contrast_posterior = true_stim_posterior(trial_contrast, beliefSTD)
    	else:
    		posterior_idx = np.argmin(np.abs(all_contrasts - trial_contrast))
    		contrast_posterior = all_posteriors[posterior_idx, :]
    
    	Q_L, Q_R = compute_QL_QR(Q, trial_contrast, contrast_posterior)
        
    	choice_dist = softmax_stay(Q_L, Q_R, beta)
    	LL = np.log(choice_dist[trial_choice])	
    
    	# Learning
    	if trial_choice == 0:
    		Q_chosen = Q_L
    	else:
    		Q_chosen = Q_R
    
    	# Laser-modulation
    	if laser == 1:
    		received_reward = reward
    	else:
    		received_reward = reward
    
    	# Update Q-values according to the aggregate reward + laser value
    	for i in range(2):
    		Q[i, trial_choice] += contrast_posterior[i] * learning_rate * (received_reward - Q_chosen)
    
    	if retrieve_ITIQ == True:
    		Q_L = np.sum(Q, axis=0)[0]
    		Q_R = np.sum(Q, axis=0)[1]
    
    
    	if retrieve_Q==True:
    		return LL, Q, Q_L, Q_R, choice_dist[1] #  choice_dist[1] = pChoice_right
        
    	else:
    		return LL, Q
    
    
    
    def session_neg_log_likelihood_stay(params, *data, pregen_all_posteriors=True, 
                                        accu=False, retrieve_Q =  False, retrieve_ITIQ = False):
    	# Unpack the arguments
    	learning_rate, beliefSTD, beta = params
    	rewards, true_contrasts, choices, lasers = data
    	num_trials = len(rewards)
        
    	if retrieve_Q==True:
    		Q_L = []
    		Q_R = []
    		pRight = []
    
    	# Generate the possible contrast list
    	all_contrasts = np.array([-0.25, -0.125, -0.0625, 0, 0.0625, 0.125, 0.25])
    	num_contrasts = len(all_contrasts)
    
    	# If True, generate all posterior distributions ahead of time to save time
    	if pregen_all_posteriors:
    		all_posteriors = np.zeros((num_contrasts, 2))
    		for idx, contrast in enumerate(all_contrasts):
    			all_posteriors[idx, :] = true_stim_posterior(contrast, beliefSTD)
    	else:
    		all_posteriors = None
    
    	# Compute the log-likelihood
    	if accu == True:
    		acc = 0
    	LL = 0
    	Q = np.zeros([2, 2])
        
    	if retrieve_Q == True:
                
    		for i in range(num_trials):
    			if i == 0:
    			    trial_LL, newQ, Q_Lt, Q_Rt, pright = trial_log_likelihood_stay(params, 
                                                [true_contrasts[i], choices[i], rewards[i], lasers[i]], 
                                                Q, all_contrasts, all_posteriors, 
                                                np.nan, i, retrieve_Q=retrieve_Q, retrieve_ITIQ=retrieve_ITIQ)
    			else:
    			    trial_LL, newQ, Q_Lt, Q_Rt, pright = trial_log_likelihood_stay(params, 
                                                [true_contrasts[i], choices[i], rewards[i], lasers[i]], 
                                                Q, all_contrasts, all_posteriors, 
                                                choices[i-1], i, retrieve_Q=retrieve_Q, retrieve_ITIQ=retrieve_ITIQ)
    
    			if (i != 0) & (np.sum(Q, axis=0)[0] != np.sum(newQ, axis=0)[0]) & (np.sum(Q, axis=0)[1] != np.sum(newQ, axis=0)[1]):
    				print('Warning, double update error in trial %d'%i)
    			LL += trial_LL
    			Q = newQ
                
    			if accu == True:
    				acc += (np.exp(trial_LL)>0.5)*1
                
    			Q_L.append(Q_Lt)
    			Q_R.append(Q_Rt)
    			pRight.append(pright)
            
    		
    	else:        
    		for i in range(num_trials):
    			if i == 0:
    			    trial_LL, newQ = trial_log_likelihood_stay(params, 
                                                [true_contrasts[i], choices[i], rewards[i], lasers[i]], 
                                                Q, all_contrasts, all_posteriors, np.nan, i)
    			else:
    			    trial_LL, newQ = trial_log_likelihood_stay(params, 
                                                [true_contrasts[i], choices[i], rewards[i], lasers[i]], 
                                                Q, all_contrasts, all_posteriors, choices[i-1], i)
    			LL += trial_LL
    			Q = newQ
                
    			if accu == True:
    				acc += (np.exp(trial_LL)>0.5)*1
                    
    
    	if retrieve_Q == True:   
    		if accu == True:
    			acc = acc/num_trials
    			return -LL,  acc, Q_L, Q_R, pRight
    		else:
    			return -LL, Q_L, Q_R, pRight
    
    	else:
    		if accu == True:
    			acc = acc/num_trials
    			return -LL,  acc
    		else:
    			return -LL
    
    
    
    
    
    # Optimize several times with different initializations and return the best fit parameters, and negative log likelihood
    
    def optimizer_stay(data, num_fits = 4, initial_guess=[0.1, 1, 1]):
    	# Accounting variables
    	best_NLL = np.Inf
    	best_x = [None, None, None]
    	buffer_NLL = []
    	buffer_x = np.empty([num_fits,len(initial_guess)])
    	# Do our fit with several different initializations
    	for i in range(num_fits):
    		print('Starting fit %d' % i)
    
    		# For every fit other than the first, construct a new initial guess
    		if i != 0:
    			lr_guess = np.random.uniform(0, 2)
    			beliefSTD_guess = np.random.uniform(0.03, 1)
    			beta_guess = np.random.uniform(0.01, 1)
    			initial_guess = [lr_guess, beliefSTD_guess, beta_guess]
    
    		# Run the fit
    		res = so.minimize(session_neg_log_likelihood_stay, initial_guess, args=data, 
                        method='L-BFGS-B', bounds=[(0, 2), (0.03, 1), (0.01, 1)])
    
    		# If this fit is better than the previous best, remember it, otherwise toss
    		buffer_x[i,:] = res.x
    		buffer_NLL.append(res.fun)
            
    		if res.fun <= best_NLL:
    			best_NLL = res.fun
    			best_x = res.x
    
    	return best_x, best_NLL, buffer_NLL, buffer_x
    
    
    
    # hardcode this for speed
    def normal_pdf(x, loc, scale):
    	factor = 1 / (np.sqrt(2 * np.pi) * scale)
    	power = -0.5 * (((x - loc) / scale) ** 2)
    
    	return factor * np.exp(power)
    
    ##### Analysis functions
    
    def accuracy_per_contrast(data, all_contrasts):
    	rewards, contrasts, choices, lasers = data
    	num_trials = len(rewards)
    
    	acc = np.zeros(len(all_contrasts))
    	trials_per_contrast = np.zeros(len(all_contrasts))
    	for i in range(num_trials):
    		reward = rewards[i]
    		contrast = contrasts[i]
    		choice = choices[i]
    		laser = lasers[i]
    
    		contrast_idx = np.argmin(np.abs(all_contrasts - contrast))
    		
    		if reward > 0:
    			acc[contrast_idx] += 1
    
    		trials_per_contrast[contrast_idx] += 1
    
    	acc /= trials_per_contrast
    
    	return acc
    
    def psychometric_curve(data, all_contrasts):
    	rewards, contrasts, choices, lasers = data
    	num_trials = len(rewards)
    
    	p_right = np.zeros(len(all_contrasts))
    	trials_per_contrast = np.zeros(len(all_contrasts))
    	for i in range(num_trials):
    		reward = rewards[i]
    		contrast = contrasts[i]
    		choice = choices[i]
    		laser = lasers[i]
    
    		contrast_idx = np.argmin(np.abs(all_contrasts - contrast))
    		
    		if choice == 1:
    			p_right[contrast_idx] += 1
    
    		trials_per_contrast[contrast_idx] += 1
    
    	p_right /= trials_per_contrast
    
    	return p_right
    
    ##### TESTING SCRIPT #####
    
    def simulation_contrast_distribution(mean_contrast, beliefSTD, all_contrasts):
    	# Compute distribution of final perceived contrasts
    	p = normal_pdf(all_contrasts, loc=mean_contrast, scale=beliefSTD)
    
    	# Renormalize
    	p /= np.sum(p)
    
    	return p
    
    
    def generate_data_stay(data, all_contrasts, learning_rate=0.3, 
                           beliefSTD=0.1, beta=0.2, 
                           stay = 1, is_verbose=False, propagate_errors = True):
    	
    	rewards = []
    	true_contrasts = []
    	choices = []
    	lasers = []
        
    	if propagate_errors == False:
    		prop = 3
    	else:
    		prop = 4
    
    	# Simulate the POMDP model
    	Q = np.zeros([2, 2])
    	for t in range(len(data[0])):
    		if is_verbose:
    			print(t)
    
    		# Pick a true stimulus and store
    		trial_contrast = data[1][t]
    		true_contrasts.append(trial_contrast)
            # Add noise
    		perceived_contrast_distribution = simulation_contrast_distribution(trial_contrast, beliefSTD, all_contrasts)
    		perceived_contrast = np.random.choice(all_contrasts, p=perceived_contrast_distribution)
            
    		contrast_posterior = [0,0]
    		contrast_posterior[0] = norm.cdf(0, loc = trial_contrast, scale = beliefSTD)
    		contrast_posterior[1] = 1 - contrast_posterior[0]
            
    		Q_L, Q_R = compute_QL_QR(Q, perceived_contrast, contrast_posterior)
    
    		
    		choice_dist = softmax_stay(Q_L, Q_R, beta)
    		choice = np.random.choice(2, p = [float(choice_dist[0]), float(choice_dist[1])])
    		choices.append(choice)
    
    		# Get reward and store it
    		if np.sign(trial_contrast) == -1 and choice == 0:
    			reward = 1
    		elif np.sign(trial_contrast) == 1 and choice == 1:
    			reward = 1
    		elif np.sign(trial_contrast) == 0:
    			reward = random.choice([0,1])      
    		else:
    			reward = 0
    
    		rewards.append(reward)
    		
    		# Add laser value on the correct condition
    		if propagate_errors == True:
    			if choice == data[prop][t]:
    			    reward += 0
    			    lasers.append(1)
    			else:
    			    lasers.append(-1)
    		else:
    			reward = data[0][t]
    			reward += 0
    			lasers.append(data[prop][t])
    		# Learn (update Q-values)
    		if choice == 0:
    			Q_chosen = Q_L
    		else:
    			Q_chosen = Q_R
            
    		contrast_posterior = [0,0]
    		contrast_posterior[0] = norm.cdf(0, loc = trial_contrast, scale = beliefSTD)
    		contrast_posterior[1] = 1 - contrast_posterior[0]
    
    		for i in range(2):
    			Q[i, choice] += contrast_posterior[i] * learning_rate * (reward - Q_chosen)
    
    	return rewards, true_contrasts, choices, lasers
    
    def transform_model_struct_2_POMDP(model_data, simulate_data):
            simulate_data.loc[simulate_data['extraRewardTrials'] == 'right', 'extraRewardTrials' ] = 1
            simulate_data.loc[simulate_data['extraRewardTrials'] == 'left', 'extraRewardTrials' ] = 0
            simulate_data.loc[simulate_data['extraRewardTrials'] == 'none', 'extraRewardTrials' ] = -1
            obj = model_data
            obj['choice'] = obj['choice'] * -1
            obj.loc[obj['choice'] == -1, 'choice'] = 0
            obj['laser_side'] = simulate_data['extraRewardTrials']
            return obj
    
    def likelihood_ratio(llmin, llmax):
        return(2*(llmax-llmin))
    
    def aic(LL,n_param):
        # Calculates Akaike Information Criterion
        aic =  2*n_param - 2*LL
        return aic
        
    def chi2_LLR(L1,L2):
        LR = likelihood_ratio(L1,L2)
        p = chi2.sf(LR, 1) # L2 has 1 DoF more than L1
        return p

    mice = np.array(['dop_8', 'dop_9', 'dop_11', 'dop_4', 'dop_7'])
    
    # Load Alex's actual data
    psy = pd.read_pickle('all_behav.pkl')
    
    train_set_size = 1
    cross_validate = False
         
    all_contrasts = np.array([-0.25  , -0.125 , -0.0625,  0.    ,  0.0625, 0.125 , 0.25  ])
    best_nphr_individual = np.zeros([len(psy.loc[psy['virus'] == 'nphr', 'mouse_name'].unique()),4])
    best_nphr_NLL_individual = np.zeros([len(psy.loc[psy['virus'] == 'nphr', 'mouse_name'].unique()),1])
    model_parameters = pd.DataFrame()
    modelled_data = pd.DataFrame()
    for i, mouse in enumerate(mice): 
            model_data_nphr, simulate_data_nphr  = \
                psy_df_to_Q_learning_model_format(psy.loc[psy['mouse_name'] == mouse], 
                                                  virus = psy.loc[psy['mouse_name'] == mouse, 'virus'].unique()[0])
            
            
            obj = transform_model_struct_2_POMDP(model_data_nphr, simulate_data_nphr)
            
            virus = psy.loc[psy['mouse_name'] == mouse, 'virus'].unique()[0]
            
            opto = obj['extraRewardTrials'].to_numpy()
            lasers = []
            for i in range(len(opto)):
                try:
                    lasers.append(int(opto[i][0]))
                except:
                    lasers.append(int(opto[i]))
        
            choices = list(obj['choice'].to_numpy())
            contrasts = list(obj['stimTrials'].to_numpy())
            rewards = list(obj['reward'].to_numpy())
            laser_side = list(obj['laser_side'].to_numpy())
        
            
            data = (rewards[:int(len(rewards)*train_set_size)],
                    contrasts[:int(len(rewards)*train_set_size)], 
                    choices[:int(len(rewards)*train_set_size)], 
                    lasers[:int(len(rewards)*train_set_size)])
            simulate_data = (rewards[:int(len(rewards)*train_set_size)], 
                             contrasts[:int(len(rewards)*train_set_size)], 
                             choices[:int(len(rewards)*train_set_size)], 
                          lasers[:int(len(rewards)*train_set_size)], 
                          laser_side[:int(len(rewards)*train_set_size)])
            
            if cross_validate == True:
                
                data = (rewards[:int(len(rewards)*train_set_size)],
                    contrasts[:int(len(rewards)*train_set_size)], 
                    choices[:int(len(rewards)*train_set_size)], 
                    lasers[:int(len(rewards)*train_set_size)])
                simulate_data_test = (rewards[int(len(rewards)*train_set_size):], 
                                      contrasts[int(len(rewards)*train_set_size):], 
                                      choices[int(len(rewards)*train_set_size):], 
                              lasers[int(len(rewards)*train_set_size):], 
                              laser_side[int(len(rewards)*train_set_size):])
            else:
                data_test = data
                simulate_data_test = simulate_data
            
    
            (best_x_stay, train_NLL_stay, buffer_NLL_stay, 
             buffer_x_stay) = optimizer_stay(data, initial_guess=[0.3, 0.05, 0.2])
            
            cv_aic_stay = aic((session_neg_log_likelihood_stay(best_x_stay,
                      *data_test, pregen_all_posteriors=True))*-1,5)
            
           
            cv_LL_stay = (session_neg_log_likelihood_stay(best_x_stay, *data_test,
                                                          pregen_all_posteriors=True))*-1
           
            
            
            _, cv_acc_stay = session_neg_log_likelihood_stay(best_x_stay, *data_test, 
                           pregen_all_posteriors=True, accu=True)
           
            
            model_parameters_mouse = pd.DataFrame()
            model_parameters_mouse['x'] = [best_x_stay]
            model_parameters_mouse['LL'] = (cv_LL_stay/len(data_test[0]))
            model_parameters_mouse['aic'] = cv_aic_stay
            model_parameters_mouse['accu'] = cv_acc_stay
            model_parameters_mouse['model_name'] = 'w_stay'
    
            
            sim_data = generate_data_stay(simulate_data_test, all_contrasts, learning_rate=best_x_stay[0],
                                       beliefSTD=best_x_stay[1], beta=best_x_stay[2])
            sim_data = pd.DataFrame(sim_data)
            
            sim_data = sim_data.rename(columns={0: "rewards", 1: "signed_contrast", 2: "simulated_choices", 3: "model_laser"})
            sim_data = np.array(sim_data)
            sim_data = pd.DataFrame(sim_data).T
            sim_data['laser'] = lasers[:int(len(rewards)*train_set_size)]
            sim_data['laser_side'] = laser_side[:int(len(rewards)*train_set_size)]
            sim_data['real_choice'] = choices[:int(len(rewards)*train_set_size)]
            sim_data['mouse_name']  = mouse
            sim_data['virus']  = virus
            sim_data['real_rewards']  = simulate_data[0]
           
            # Concatenate with general dataframes
            model_parameters_mouse['mouse'] = mouse
            model_parameters_mouse['virus'] = virus
            
            # Concatenate with general dataframes
            model_parameters = pd.concat([model_parameters, model_parameters_mouse])
            modelled_data = pd.concat([modelled_data, sim_data])
    
    return model_parameters



if __name__ == '__main__':
    model_control1 = model_control()
    model_wo_stay1 = model_wo_stay()
    model_w_stay_multiply_RPE1 = model_w_stay_multiply_RPE()
    model_wo_stay_multiply_RPE1 = model_wo_stay_multiply_RPE()
    
    
    model_2_laser_w_stay1 = model_2_laser_w_stay()
    model_2_laser_wo_stay1 = model_2_laser_wo_stay()
    model_wo_laser_w_stay1 = model_wo_laser_w_stay()
    model_wo_laser_wo_stay1 = model_wo_laser_wo_stay()
    
    # Plot
    model_control1['model_name'] = 'Model Control'
    model_wo_stay1['model_name'] = 'Model - No Stay'
    model_w_stay_multiply_RPE1['model_name'] = 'Model - Laser Multiplies'
    model_wo_stay_multiply_RPE1['model_name'] = 'Model - Laser Multiplies + No Stay'
    model_2_laser_w_stay1['model_name'] = 'Model - 2 Laser parameters'
    model_2_laser_wo_stay1['model_name'] = 'Model - 2 Laser parameters + No Stay'
    model_wo_laser_w_stay1['model_name'] = 'Model - No Laser'
    model_wo_laser_wo_stay1['model_name'] = 'Model - No Laser + No Stay'
    
    models = pd.concat([model_control1, model_wo_stay1,
                        model_w_stay_multiply_RPE1, model_wo_stay_multiply_RPE1, 
                        model_2_laser_w_stay1, model_2_laser_wo_stay1, 
                        model_wo_laser_w_stay1, model_wo_laser_wo_stay1])
    
    models.to_pickle('./fitted_parameters.pkl')
    
    # FIG 1 - COMPARISON OF MODEL ACCURACY
    fig, ax  = plt.subplots(figsize =(5,10))
    sns.swarmplot(data = models, x = 'model_name', y = 'accu', hue = 'virus',
                  order = models['model_name'].unique())
    sns.boxplot(data = models, x = 'model_name', y = 'accu',
                  order = models['model_name'].unique(), color = 'white')
    labels = models['model_name'].unique()
    ax.set_xticklabels(labels,rotation = 90)
    plt.ylim(0.6, 0.9)
    ax.set_xlabel('Model Type')
    ax.set_ylabel('Accuracy')
    sns.despine()
    plt.tight_layout()
    plt.savefig('model_comparison_accu.png', dpi=300)
    
    # FIG 2 - COMPARISON OF MODEL ACCURACY
    fig, ax  = plt.subplots()
    sns.swarmplot(data = models, x = 'model_name', y = 'LL', hue = 'virus',
                  order = models['model_name'].unique())
    sns.boxplot(data = models, x = 'model_name', y = 'LL',
                  order = models['model_name'].unique(), color = 'white')
    labels = models['model_name'].unique()
    ax.set_xticklabels(labels,rotation = 90)
    plt.ylim(-0.7, -0.3)
    ax.set_xlabel('Model Type')
    ax.set_ylabel('Mean LL / Trial')
    sns.despine()
    
    plt.savefig('model_comparison_LL.png', dpi=300)
    # FIG 3 - MODEL PARAMETERS IN EACH MODEL
    def boxplot_model_parameters_per_mouse(model_parameters, 
                                       model_type= 'w_stay'):
        '''
        Notes: Plots learned parameters across virus
        '''
        fig, ax =  plt.subplots()
        sns.set(style='white')
        model = model_parameters.loc[model_parameters['model_name'] == model_type, 
                                     ['x', 'virus']]
        
        if model_type == 'Model Control':
            params = [r'$\alpha$', r'$\sigma$', r'$\psi$',
                  r'$\tau$', r'$\gamma$']
        if model_type == 'Model - No Stay':
            params = [r'$\alpha$', r'$\sigma$', r'$\psi$',
                  r'$\tau$']
        if model_type == 'Model - Laser Multiplies':
            params = [r'$\alpha$', r'$\sigma$', r'$\psi$',
                  r'$\tau$', r'$\gamma$']
        if model_type == 'Model - Laser Multiplies + No Stay':
            params = [r'$\alpha$', r'$\sigma$', r'$\psi$',
                  r'$\tau$'] 
        if model_type == 'Model - 2 Laser parameters':
            params = [r'$\alpha$', r'$\sigma$', r'$\psi$',
                  r'$\tau$', r'$\gamma$', r'$\chi$']
        if model_type == 'Model - 2 Laser parameters + No Stay':
            params = [r'$\alpha$', r'$\sigma$', r'$\psi$',
                  r'$\tau$', r'$\chi$']
        if model_type == 'Model - No Laser':
            params = [r'$\alpha$', r'$\sigma$',
                  r'$\tau$', r'$\gamma$']
        if model_type == 'Model - No Laser + No Stay': 
            params = [r'$\alpha$', r'$\sigma$', r'$\tau$']
        
        mod = pd.DataFrame(columns = ['params', 'virus'])
        for i in range(len(model)):
            temp_mod = pd.DataFrame(model['x'].iloc[i])
            temp_mod['params'] = params[:len(temp_mod)]
            temp_mod['virus'] = model.iloc[i,1]
            mod = mod.append(temp_mod)
        sns.swarmplot(data = mod,  x = 'params', y = 0,  hue = 'virus', 
                      palette = ['dodgerblue', 'orange'], split = False)
        if (model_type == 'Model - Laser Multiplies') | \
            (model_type == 'Model - Laser Multiplies + No Stay'):
                ax.axhline(1, ls='--', color = 'k')
                
        else:
            ax.axhline(0, ls='--', color = 'k')
        ax.set_xlabel('Model Parameter')
        ax.set_ylabel('Fitted Coef')
        sns.despine()
    
    fig, ax = plt.subplots(4,2, figsize = (10,20))
    plt.sca(ax[0,0])
    boxplot_model_parameters_per_mouse(models, 
                                       model_type= 'Model Control')
    plt.sca(ax[0,1])
    boxplot_model_parameters_per_mouse(models, 
                                       model_type= 'Model - No Stay')
    plt.sca(ax[1,0])
    boxplot_model_parameters_per_mouse(models, 
                                       model_type= 'Model - 2 Laser parameters')
    plt.sca(ax[1,1])
    boxplot_model_parameters_per_mouse(models, 
                                       model_type= 'Model - 2 Laser parameters + No Stay')
    plt.sca(ax[2,0])
    boxplot_model_parameters_per_mouse(models, 
                                       model_type= 'Model - No Laser')
    plt.sca(ax[2,1])
    boxplot_model_parameters_per_mouse(models, 
                                       model_type= 'Model - No Laser + No Stay')
    plt.sca(ax[3,0])
    boxplot_model_parameters_per_mouse(models, 
                                       model_type= 'Model - Laser Multiplies')
    plt.sca(ax[3,1])
    boxplot_model_parameters_per_mouse(models, 
                                       model_type= 'Model - Laser Multiplies + No Stay')
    
    plt.tight_layout()
    plt.savefig('model_comparison_parameters.pdf', dpi=300)
    
    # Statistical analyses of different models
    
    def likelihood_ratio(llmin, llmax):
        return(2*(llmax-llmin))
    
    def chi2_LLR(L1,L2, df = 1):
        LR = likelihood_ratio(L1,L2)
        p = chi2.sf(LR, df) # L2 has 1 DoF more than L1
        return p
    
    LLs = models.groupby(['model_name']).mean()
    n_trials = len(psy)
    LLs['LL'] = LLs*n_trials
    
    L1 = LLs.loc[LLs.index== 'Model - No Stay', 'LL'][0]
    L2 = LLs.loc[LLs.index== 'Model Control', 'LL'][0]
    print('Model - No Stay ' + '+ ' + 'Model Control' + str(chi2_LLR(L1,L2)))
    
    L2 = LLs.loc[LLs.index== 'Model - 2 Laser parameters', 'LL'][0]
    L1 = LLs.loc[LLs.index== 'Model Control', 'LL'][0]
    print('Model - 2 Laser parameters' + '+ ' + 'Model Control' + str(chi2_LLR(L1,L2)))
    
    L2 = LLs.loc[LLs.index== 'Model - 2 Laser parameters + No Stay', 'LL'][0]
    L1 = LLs.loc[LLs.index== 'Model - No Stay', 'LL'][0]
    print('Model - 2 Laser parameters + No Stay' + '+ ' + 'Model - No Stay' + str(chi2_LLR(L1,L2)))
    
    L1 = LLs.loc[LLs.index== 'Model - No Laser', 'LL'][0]
    L2 = LLs.loc[LLs.index== 'Model Control', 'LL'][0]
    print('Model - No Laser' + '+ ' + 'Model Control' + str(chi2_LLR(L1,L2)))
    
    L1 = LLs.loc[LLs.index== 'Model - No Laser + No Stay', 'LL'][0]
    L2 = LLs.loc[LLs.index== 'Model - No Stay', 'LL'][0]
    print('Model - No Laser + No Stay' + '+ ' + 'Model - No Stay' + str(chi2_LLR(L1,L2)))