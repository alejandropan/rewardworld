#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed Jul 31 13:22:38 2019

@author: alex
"""

import matplotlib.pyplot as plt
import pandas as pd
## CONNECT TO datajoint
import datajoint as dj
dj.config['database.host'] = 'datajoint.internationalbrainlab.org'
from ibl_pipeline.analyses import behavior as behavior_analysis
from ibl_pipeline import reference, subject, behavior
from load_mouse_data_datajoint import *  # this has all plotting functions
import seaborn as sns

key = ((subject.Subject()  & 'sex!="U"') * (behavior.TrialSet() & 'n_trials > 100') * (subject.SubjectLab()) * (behavior_analysis.SessionTrainingStatus() & 'training_status="ready for ephys"  ')).fetch('KEY')
trials_ibl = pd.DataFrame.from_dict((subject.Subject() * behavior.TrialSet.Trial & key).fetch(as_dict=True))

trials_ibl['signed_contrasts'] = trials_ibl['trial_stim_contrast_right'] - trials_ibl['trial_stim_contrast_left']

trials_ibl = trials_ibl.rename(index=str, columns={"session_start_time": "ses", 
                                      "subject_uuid": "mouse_name", 
                                      "trial_feedback_type": "feedbackType", 
                                      "trial_response_choice":"choice"})

trials_ibl.loc[(trials_ibl['choice']=='CW'),'choice'] = -1
trials_ibl.loc[(trials_ibl['choice']=='CCW'), 'choice'] = 1
trials_ibl.loc[(trials_ibl['choice']=='No Go'), 'choice'] = 0
#Select only biased blocks
psy_df =  trials_ibl.loc[(trials_ibl['trial_stim_prob_left'] == 0.8) | (trials_ibl['trial_stim_prob_left'] == 0.2)]


#Â£Calculate probability of making the same choice after error and reward
data =  psy_df.loc[ :, ['mouse_name', 'feedbackType', 'signed_contrasts', 'choice','ses']]
#Rewardedchoices: 
data.loc[(data['choice'] == -1) & (data['feedbackType'] == -1) , 'rchoice']  = 0
data.loc[(data['choice'] == -1) & (data['feedbackType'] == 1) , 'rchoice']  = -1    
data.loc[(data['choice'] == 1) & (data['feedbackType'] == 1) , 'rchoice']  = 1
data.loc[(data['choice'] == 1) & (data['feedbackType'] == -1) , 'rchoice']  = 0

#Unrewarded choices: 
data.loc[(data['choice'] == -1) & (data['feedbackType'] == -1) , 'uchoice']  = -1
data.loc[(data['choice'] == -1) & (data['feedbackType'] == 1) , 'uchoice']  = 0
data.loc[(data['choice'] == 1) & (data['feedbackType'] == 1) , 'uchoice']  = 0
data.loc[(data['choice'] == 1) & (data['feedbackType'] == -1) , 'uchoice']  = 1



#drop no goes
data = data.drop(data.index[data['choice'] == 0],axis=0)
#Reward history column
no_tback = 1 #no of trials back    
for mouse in (data['mouse_name'].unique()):
    for date in sorted(data.loc[(data['mouse_name'] == mouse),'ses'].unique()):
        for i in range(no_tback):
            data.loc[data['ses'] == date,'rchoice%s' %str(i+1)] =  data.loc[data['ses'] == date,'rchoice'].shift(i+1) #no point in 0 shift
            data.loc[data['ses'] == date,'uchoice%s' %str(i+1)] =  data.loc[data['ses'] == date,'uchoice'].shift(i+1) #no point in 0 shift
            data.loc[data['ses'] == date,'feedback%s' %str(i+1)] =  data.loc[data['ses'] == date,'feedbackType'].shift(i+1) #Redundant for data quality control
#Calculate reward proabilities
#Percentage of stay trials precceeded by a rewarded trial
stay_after_reward = sum(data['rchoice1'] == data['choice'])/sum(data['rchoice1'] != 0)
stay_after_error  = sum(data['uchoice1'] == data['choice'])/sum(data['rchoice1'] == 0)

#Based on feedback type
stay_after_reward1 = sum(data['rchoice1'] == data['choice'])/sum(data['feedback1'] == 1)
stay_after_error1  = sum(data['uchoice1'] == data['choice'])/sum(data['feedback1'] == -1)


## Now let's use Anne's selection
use_subjects = (subject.Subject() & 'subject_birth_date > "2019-03-01"' \
			   & 'subject_line IS NULL OR subject_line="C57BL/6J"') * subject.SubjectLab()
use_subjects = subject.Subject * subject.SubjectLab * subject.SubjectProject & 'subject_project="ibl_neuropixel_brainwide_01"'

sess = (acquisition.Session & (behavior.TrialSet.Trial() & 'ABS(trial_stim_contrast_left-0)<0.0001' \
	& 'ABS(trial_stim_contrast_right-0)<0.0001') & 'task_protocol like "%biasedChoiceWorld%"') * use_subjects
b 		= (behavior.TrialSet.Trial & sess) * subject.Subject() * subject.SubjectLab()
bdat 	= pd.DataFrame(b.fetch(order_by='subject_nickname, session_start_time, trial_id'))

trials_anne = bdat.rename(index=str, columns={"session_start_time": "ses", 
                                      "subject_uuid": "mouse_name", 
                                      "trial_feedback_type": "feedbackType", 
                                      "trial_response_choice":"choice"})

trials_anne.loc[(trials_anne['choice']=='CW'),'choice'] = -1
trials_anne.loc[(trials_anne['choice']=='CCW'), 'choice'] = 1
trials_anne.loc[(trials_anne['choice']=='No Go'), 'choice'] = 0
    
psy_anne =  trials_anne.loc[(trials_anne['trial_stim_prob_left'] == 0.8) | (trials_anne['trial_stim_prob_left'] == 0.2)]
data1 =  psy_anne.loc[ :, ['mouse_name', 'feedbackType', 'signed_contrasts', 'choice','ses']]


data1.loc[(data1['choice'] == -1) & (data1['feedbackType'] == -1) , 'rchoice']  = 0
data1.loc[(data1['choice'] == -1) & (data1['feedbackType'] == 1) , 'rchoice']  = -1    
data1.loc[(data1['choice'] == 1) & (data1['feedbackType'] == 1) , 'rchoice']  = 1
data1.loc[(data1['choice'] == 1) & (data1['feedbackType'] == -1) , 'rchoice']  = 0

data1.loc[(data1['choice'] == -1) & (data1['feedbackType'] == -1) , 'uchoice']  = -1
data1.loc[(data1['choice'] == -1) & (data1['feedbackType'] == 1) , 'uchoice']  = 0
data1.loc[(data1['choice'] == 1) & (data1['feedbackType'] == 1) , 'uchoice']  = 0
data1.loc[(data1['choice'] == 1) & (data1['feedbackType'] == -1) , 'uchoice']  = 1

data1 = data1.drop(data1.index[data1['choice'] == 0],axis=0)

no_tback = 1 

for mouse in (data1['mouse_name'].unique()):
    for date in sorted(data1.loc[(data1['mouse_name'] == mouse),'ses'].unique()):
        for i in range(no_tback):
            data1.loc[data1['ses'] == date,'rchoice%s' %str(i+1)] =  data1.loc[data1['ses'] == date,'rchoice'].shift(i+1) #no point in 0 shift
            data1.loc[data1['ses'] == date,'uchoice%s' %str(i+1)] =  data1.loc[data1['ses'] == date,'uchoice'].shift(i+1) #no point in 0 shift
            data1.loc[data1['ses'] == date,'feedback%s' %str(i+1)] =  data1.loc[data1['ses'] == date,'feedbackType'].shift(i+1) #Redundant for data quality control
#Calculate reward proabilities
#Percentage of stay trials precceeded by a rewarded trial
stay_after_reward_anne = sum(data1['rchoice1'] == data1['choice'])/sum(data1['rchoice1'] != 0) 
stay_after_error_anne  = sum(data1['uchoice1'] == data1['choice'])/sum(data1['rchoice1'] == 0)

#Based on feedback type
stay_after_reward1_anne = sum(data1['rchoice1'] == data1['choice'])/sum(data1['feedback1'] == 1)
stay_after_error1_anne  = sum(data1['uchoice1'] == data1['choice'])/sum(data1['feedback1'] == -1)





##Using Anne's history functions

behav_biased 	= dj2pandas(bdat)
print(behav_biased.tail(n=10))

# code for history
behav_biased['previous_choice'] 		= behav_biased.choice.shift(1)
behav_biased.loc[behav_biased.previous_choice == 0, 'previous_choice'] = np.nan
behav_biased['previous_outcome'] 		= behav_biased.trial_feedback_type.shift(1)
behav_biased.loc[behav_biased.previous_outcome == 0, 'previous_outcome'] = np.nan
behav_biased['previous_contrast'] 		= np.abs(behav_biased.signed_contrast.shift(1))
behav_biased['previous_choice_name'] 	= behav_biased['previous_choice'].map({-1:'left', 1:'right'})
behav_biased['previous_outcome_name']	= behav_biased['previous_outcome'].map({-1:'post-error', 1:'post-correct'})